

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

    <title>Tutorial &#8212; Intel® Deep Learning Streamer (Intel® DL Streamer)  documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=5b4479735964841361fd" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=5b4479735964841361fd" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../_static/doxyrest-pygments.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=5b4479735964841361fd" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd" />
  <script src="../_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=5b4479735964841361fd"></script>

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/sphinx_highlight.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script src="../_static/target-highlight.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'get_started/tutorial';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Quick Start Guide for Media Analytics on Intel® Data Center GPU Flex Series" href="flex_series/quick_start_guide.html" />
    <link rel="prev" title="Uninstall Guide Ubuntu" href="install/uninstall_guide_ubuntu.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
  
    <p class="title logo__title">Intel® Deep Learning Streamer (Intel® DL Streamer)  documentation</p>
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 current active has-children"><a class="reference internal" href="get_started_index.html">Get Started</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="hardware_requirements.html">Hardware Requirements</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="install/install_guide_index.html">Install Guide</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="install/install_guide_ubuntu.html">Install Guide Ubuntu</a></li>
<li class="toctree-l3"><a class="reference internal" href="install/uninstall_guide_ubuntu.html">Uninstall Guide Ubuntu</a></li>
</ul>
</li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Tutorial</a></li>
<li class="toctree-l2"><a class="reference internal" href="flex_series/quick_start_guide.html">Quick Start Guide for Media Analytics on Intel® Data Center GPU Flex Series</a></li>



<li class="toctree-l2"><a class="reference external" href="https://github.com/dlstreamer/dlstreamer/blob/master/samples/gstreamer/README.md">Samples</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../dev_guide/dev_guide_index.html">Developer Guide</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../dev_guide/metadata.html">Metadata</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../dev_guide/model_preparation.html">Model Preparation</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../dev_guide/yolov5_model_preparation.html">Yolov5 Model Preparation Example</a></li>

<li class="toctree-l3"><a class="reference internal" href="../dev_guide/yolo_model_preparation.html">Yolo Models Preparation</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../dev_guide/model_proc_file.html">Model-proc File</a></li>
<li class="toctree-l2"><a class="reference internal" href="../dev_guide/model_info_xml.html">Model Info Section</a></li>
<li class="toctree-l2"><a class="reference internal" href="../dev_guide/how_to_create_model_proc_file.html">How to Create Model-proc File</a></li>
<li class="toctree-l2"><a class="reference internal" href="../dev_guide/python_bindings.html">Python Bindings</a></li>
<li class="toctree-l2"><a class="reference internal" href="../dev_guide/custom_processing.html">Custom Processing</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../dev_guide/object_tracking.html">Object Tracking</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../dev_guide/deepsort_implementation.html">DeepSORT tracking support</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../dev_guide/gpu_device_selection.html">GPU device selection</a></li>
<li class="toctree-l2"><a class="reference internal" href="../dev_guide/profiling.html">Profiling with Intel VTune™</a></li>
<li class="toctree-l2"><a class="reference internal" href="../dev_guide/converting_deepstream_to_dlstreamer.html">Converting NVIDIA DeepStream Pipelines to Intel® Deep Learning Streamer (Intel® DL Streamer) Pipeline Framework</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../dev_guide/how_to_contribute.html">How to Contribute</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../dev_guide/coding_style.html">Coding Style</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../dev_guide/latency_tracer.html">Latency Tracer</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../elements/elements.html">Elements</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../elements/gvadetect.html">gvadetect</a></li>
<li class="toctree-l2"><a class="reference internal" href="../elements/gvaclassify.html">gvaclassify</a></li>
<li class="toctree-l2"><a class="reference internal" href="../elements/gvainference.html">gvainference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../elements/gvaaudiodetect.html">gvaaudiodetect</a></li>
<li class="toctree-l2"><a class="reference internal" href="../elements/gvatrack.html">gvatrack</a></li>
<li class="toctree-l2"><a class="reference internal" href="../elements/gvametaconvert.html">gvametaconvert</a></li>
<li class="toctree-l2"><a class="reference internal" href="../elements/gvametapublish.html">gvametapublish</a></li>
<li class="toctree-l2"><a class="reference internal" href="../elements/gvametaaggregate.html">gvametaaggregate</a></li>
<li class="toctree-l2"><a class="reference internal" href="../elements/gvapython.html">gvapython</a></li>
<li class="toctree-l2"><a class="reference internal" href="../elements/gvawatermark.html">gvawatermark</a></li>
<li class="toctree-l2"><a class="reference internal" href="../elements/gvafpscounter.html">gvafpscounter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../elements/python_object_association.html">python_object_association</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../supported_models.html">Supported Models</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../api_ref/api_reference.html">API Reference</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../api_ref/page_index.html">Intel® Deep Learning Streamer (Intel® DL Streamer) API reference</a></li>




<li class="toctree-l2 has-children"><a class="reference internal" href="../api_ref/global.html">Global Namespace</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-9"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api_ref/namespace_gstgva.html">namespace gstgva</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-10"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_ref/namespace_gstgva_region_of_interest.html">namespace gstgva::region_of_interest</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_ref/namespace_gstgva_tensor.html">namespace gstgva::tensor</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_ref/namespace_gstgva_video_frame.html">namespace gstgva::video_frame</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api_ref/enum_GVALayout.html">enum GVALayout</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api_ref/enum_GVAPrecision.html">enum GVAPrecision</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api_ref/struct_GstGVAAudioEventMeta.html">struct GstGVAAudioEventMeta</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-11"><i class="fa-solid fa-chevron-down"></i></label><ul class="simple">
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api_ref/struct__GstGVAJSONMeta.html">struct _GstGVAJSONMeta</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-12"><i class="fa-solid fa-chevron-down"></i></label><ul class="simple">
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api_ref/struct__GstGVATensorMeta.html">struct _GstGVATensorMeta</a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-13"><i class="fa-solid fa-chevron-down"></i></label><ul class="simple">
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../architecture_2.0/architecture_2.0.html">Architecture 2.0 [Preview]</a><input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-14"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../architecture_2.0/migration_guide.html">Migration to 2.0</a></li>
<li class="toctree-l2"><a class="reference internal" href="../architecture_2.0/cpp_interfaces.html">① Memory Interop and C++ abstract interfaces</a></li>
<li class="toctree-l2"><a class="reference internal" href="../architecture_2.0/cpp_elements.html">② C++ elements</a></li>
<li class="toctree-l2"><a class="reference internal" href="../architecture_2.0/gstreamer_elements.html">③ GStreamer Elements</a></li>
<li class="toctree-l2"><a class="reference internal" href="../architecture_2.0/gstreamer_bins.html">③ GStreamer Bin Elements</a></li>
<li class="toctree-l2"><a class="reference internal" href="../architecture_2.0/python_bindings.html">③ Python Bindings</a></li>
<li class="toctree-l2"><a class="reference internal" href="../architecture_2.0/pytorch_inference.html">PyTorch tensor inference [Preview]</a></li>
<li class="toctree-l2"><a class="reference internal" href="../architecture_2.0/elements_list.html">Elements 2.0</a></li>
<li class="toctree-l2"><a class="reference internal" href="../architecture_2.0/packaging.html">Packaging</a></li>
<li class="toctree-l2"><a class="reference internal" href="../architecture_2.0/samples_2.0.html">Samples 2.0</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../architecture_2.0/api_ref/index.html">API 2.0 Reference</a><input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-15"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../architecture_2.0/api_ref/global.html">Global Namespace</a><input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-16"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../architecture_2.0/api_ref/namespace_GVA.html">namespace GVA</a></li>
<li class="toctree-l4"><a class="reference internal" href="../architecture_2.0/api_ref/namespace_dlstreamer.html">namespace dlstreamer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../architecture_2.0/api_ref/enum_GVALayout.html">enum GVALayout</a></li>
<li class="toctree-l4"><a class="reference internal" href="../architecture_2.0/api_ref/enum_GVAPrecision.html">enum GVAPrecision</a></li>
<li class="toctree-l4"><a class="reference internal" href="../architecture_2.0/api_ref/struct_GstGVAAudioEventMeta.html">struct GstGVAAudioEventMeta</a></li>
<li class="toctree-l4"><a class="reference internal" href="../architecture_2.0/api_ref/struct__GstGVAJSONMeta.html">struct _GstGVAJSONMeta</a></li>
<li class="toctree-l4"><a class="reference internal" href="../architecture_2.0/api_ref/struct__GstGVATensorMeta.html">struct _GstGVATensorMeta</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/get_started/tutorial.rst" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.rst</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Tutorial</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#about-gstreamer">About GStreamer</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pipelines">Pipelines</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#elements">Elements</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#properties">Properties</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction-to-intel-deep-learning-streamer-intel-dl-streamer-pipeline-framework">Introduction to Intel® Deep Learning Streamer (Intel® DL Streamer) Pipeline Framework</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tutorial-setup">Tutorial Setup</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tutorial-setup-for-docker">Tutorial Setup for Docker</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-1-build-object-detection-pipeline">Exercise 1 - Build object detection pipeline</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pipeline">Pipeline</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#pipeline-with-a-web-camera-video-stream-input-first-optional-add-on-to-exercise-1">Pipeline with a Web Camera Video Stream Input (First optional add-on to Exercise 1)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#pipeline-with-an-rtsp-input-second-optional-add-on-to-exercise-1">Pipeline with an RTSP Input (Second optional add-on to Exercise 1)</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-2-build-object-classification-pipeline">Exercise 2: Build object classification pipeline</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pipeline-1">Pipeline</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-3-use-object-tracking-to-improve-performance">Exercise 3: Use object tracking to improve performance</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pipeline-2">Pipeline</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-4-publish-inference-results">Exercise 4: Publish Inference Results</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#setup">Setup</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pipeline-3">Pipeline</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#next-steps">Next Steps</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section id="tutorial">
<h1>Tutorial<a class="headerlink" href="#tutorial" title="Permalink to this heading">#</a></h1>
<p>In this tutorial, you will learn how to build video analytics pipelines
using Intel® Deep Learning Streamer (Intel® DL Streamer) Pipeline Framework.</p>
<ul class="simple">
<li><p><a class="reference external" href="#about-gstreamer">About GStreamer</a></p></li>
<li><p><a class="reference external" href="#introduction-to-intel-deep-learning-streamer-intel-dl-streamer-pipeline-framework">Introduction to Intel® Deep Learning Streamer (Intel® DL Streamer) Pipeline Framework</a></p></li>
<li><p><a class="reference external" href="#tutorial-setup">Tutorial Setup</a></p></li>
<li><p><a class="reference external" href="#tutorial-setup-for-docker">Tutorial Setup for Docker</a></p></li>
<li><p><span class="xref std std-ref">Exercise 1 - Build object detection pipeline</span></p></li>
<li><p><a class="reference internal" href="#object-classification"><span class="std std-ref">Exercise 2 - Build object classification pipeline</span></a></p></li>
<li><p><a class="reference internal" href="#object-tracking"><span class="std std-ref">Exercise 3 - Use object tracking to improve performance</span></a></p></li>
<li><p><a class="reference internal" href="#result-publishing"><span class="std std-ref">Exercise 4 - Publish the inference results to a `.json` file</span></a></p></li>
</ul>
<section id="about-gstreamer">
<h2>About GStreamer<a class="headerlink" href="#about-gstreamer" title="Permalink to this heading">#</a></h2>
<p>In this section we introduce basic GStreamer* concepts that you will
use in the rest of the tutorial. If you are already familiar with
GStreamer feel free to skip ahead to the next section - <a class="reference external" href="#introduction-to-intel-deep-learning-streamer-intel-dl-streamer-pipeline-framework">Introduction to
Intel® DL Streamer Pipeline Framework</a>.</p>
<p><a class="reference external" href="https://gstreamer.freedesktop.org/">GStreamer</a> is a flexible, fast
and multiplatform open-source multimedia framework. It has an easy to
use command line tool for running pipelines, as well as an API with
bindings in C*, Python*, JavaScript* and more. In this tutorial we will use
the GStreamer command line tool gst-launch-1.0. For more information and
examples please refer to the online documentation for
<a class="reference external" href="https://gstreamer.freedesktop.org/documentation/tools/gst-launch.html?gi-language=c">gst-launch-1.0</a>.</p>
<section id="pipelines">
<h3>Pipelines<a class="headerlink" href="#pipelines" title="Permalink to this heading">#</a></h3>
<p>The command line tool <strong>gst-launch-1.0</strong> enables developers to describe
a media analytics pipeline as a series of connected elements. The list of
elements, their configuration properties, and their connections are all
specified as a list of strings separated by exclamation marks (!).
<strong>gst-launch-1.0</strong> parses the string and instantiates the software modules
which perform the individual media analytics operations. Internally, the
GStreamer library constructs a pipeline object that contains the
individual elements and handles common operations such as clocking,
messaging, and state changes.</p>
<p>Example: gst-launch-1.0 videotestsrc ! ximagesink</p>
</section>
<section id="elements">
<h3>Elements<a class="headerlink" href="#elements" title="Permalink to this heading">#</a></h3>
<p>An
<a class="reference external" href="https://gstreamer.freedesktop.org/documentation/application-development/basics/elements.html?gi-language=c">element</a>
is the fundamental building block of a pipeline. Elements perform
specific operations on incoming frames and then push the resulting
frames downstream for further processing. Elements are linked together
textually by exclamation marks (!) with the full chain of elements
representing the entire pipeline. Each element will take data from its
upstream element, process it and then output the data for processing by
the next element.</p>
<p>Elements designated as source elements provide input into the pipeline
from external sources. In this tutorial we use the
<a class="reference external" href="https://gstreamer.freedesktop.org/documentation/coreelements/filesrc.html?gi-language=c#filesrc">filesrc</a>
element that reads input from a local file.</p>
<p>Elements designated as sink elements represent the final stage of a
pipeline. As an example, a sink element could write transcoded frames to
a file on the local disk or open a window to render the video content to
the screen or even restream the content via RTSP. We will use the
standard
<a class="reference external" href="https://gstreamer.freedesktop.org/documentation/xvimagesink/index.html?gi-language=c">xvimagesink</a>
element to render the video frames on a local display.</p>
<p>We will also use the
<a class="reference external" href="https://gstreamer.freedesktop.org/documentation/playback/decodebin.html#decodebin">decodebin</a>
utility element. The <strong>decodebin</strong> element constructs a concrete set of
decode operations based on the given input format and the decoder and
demuxer elements available in the system. At a high level, the <strong>decodebin</strong>
abstracts the individual operations required to take encoded frames and
produce raw video frames suitable for image transformation and
inferencing.</p>
</section>
<section id="properties">
<h3>Properties<a class="headerlink" href="#properties" title="Permalink to this heading">#</a></h3>
<p>Elements are configured using key-value pairs called properties. As an
example, the filesrc element has a property named location which
specifies the file path for input.</p>
<p>Example: filesrc location=cars_1900.mp4</p>
<p>The documentation for each element, which can be viewed using the
command line tool <strong>gst-inspect-1.0</strong>, describes its properties as well as
the valid range of values for each property.</p>
</section>
</section>
<section id="introduction-to-intel-deep-learning-streamer-intel-dl-streamer-pipeline-framework">
<h2>Introduction to Intel® Deep Learning Streamer (Intel® DL Streamer) Pipeline Framework<a class="headerlink" href="#introduction-to-intel-deep-learning-streamer-intel-dl-streamer-pipeline-framework" title="Permalink to this heading">#</a></h2>
<p>Intel® DL Streamer Pipeline Framework is an easy way to construct media analytics
pipelines using Intel® Distribution of OpenVINO™ toolkit. It leverages
the open source media framework GStreamer to provide optimized media operations and
<a class="reference external" href="https://docs.openvino.ai/latest/openvino_docs_OV_UG_OV_Runtime_User_Guide.html">Deep Learning Inference Engine</a>
from OpenVINO™ Toolkit to provide optimized inference.</p>
<p>The elements packaged in the Intel® DL Streamer Pipeline Framework binary release can be divided into three categories:</p>
<ul class="simple">
<li><p>Elements for optimized streaming media operations (usb and ip camera
support, file handling, decode, color-space-conversion, scaling,
encoding, rendering, etc.). These elements are developed by the larger
GStreamer community.</p></li>
<li><p>Elements that use the Deep Learning Inference
Engine from OpenVINO™ Toolkit or OpenCV for optimized video analytics
(detection, classification, tracking). These elements are provided as
part of the Pipeline Framework’s GVA plugin.</p></li>
<li><p>Elements that convert and
publish inference results to the screen as overlaid bounding boxes, to a
file as a list of JSON Objects, or to popular message brokers (Kafka or
MQTT) as JSON messages. These elements are provided as part of the DL
Streamer’s GVA plugin.</p></li>
</ul>
<p>The elements in the last two categories above are part of Pipeline Framework’s
GVA plugin and start with the prefix ‘gva’. We will describe the ‘gva’
elements used in this tutorial with some important properties here.
Refer to <a class="reference internal" href="../elements/elements.html"><span class="doc">Intel® DL Streamer elements</span></a> page for more details.</p>
<ul class="simple">
<li><p><a class="reference internal" href="../elements/gvadetect.html"><span class="doc">gvadetect</span></a>
- Runs detection with the Inference Engine from OpenVINO™ Toolkit. We
will use it to detect vehicles in a frame and output their bounding
boxes aka Regions of Interest (ROI).</p>
<ul>
<li><p>model - path to the inference model network file</p></li>
<li><p>device - device to run inferencing on</p></li>
<li><p>inference-interval - interval between inference requests, the
bigger the value, the better the throughput. i.e. setting this
property to 1 would mean run detection on every frame while
setting it to 5 would run detection on every fifth frame.</p></li>
</ul>
</li>
<li><p><a class="reference internal" href="../elements/gvaclassify.html"><span class="doc">gvaclassify</span></a>
- Runs classification with the Inference Engine from OpenVINO™
Toolkit. We will use it to label the bounding boxes that gvadetect
outputs, with the type and color of the vehicle.</p>
<ul>
<li><p>model - path to the inference model network file</p></li>
<li><p>model-proc - path to the model-proc file. A model-proc file
describes the model input and output layer format. The model-proc
file in this tutorial describes the output layer name and labels
(person and vehicle) of objects it detects. See <a class="reference internal" href="../dev_guide/model_proc_file.html"><span class="doc">model-proc</span></a>
for more information.</p></li>
<li><p>device - device to run inferencing on</p></li>
</ul>
</li>
<li><p><a class="reference internal" href="../elements/gvatrack.html"><span class="doc">gvatrack</span></a>
- Identifies objects in frames where detection is skipped and assigns
unique ID to objects. This allows us to run object detection on fewer
frames and increases overall throughput while still tracking the
position and type of objects in every frame.</p></li>
<li><p><a class="reference internal" href="../elements/gvawatermark.html"><span class="doc">gvawatermark</span></a>
- Overlays detection and classification results on top of video data.
We will do exactly that. Parse the detected vehicle results metadata
and create a video frame rendered with the bounding box aligned to
the vehicle position; parse the classified vehicle result and label
it on the bounding box.</p></li>
</ul>
<p>In addition to <em>gvadetect</em> and <em>gvaclassify</em>, you can use
<em>gvainference</em> for running inference with any CNN model not supported
by gvadetect or gvaclassify. Also, instead of visualizing the inference
results, as shown in this tutorial, you can publish them to MQTT, Kafka
or a file using <em>gvametaconvert</em> and <em>gvametapublish</em> of Intel® DL Streamer.</p>
</section>
<section id="tutorial-setup">
<h2>Tutorial Setup<a class="headerlink" href="#tutorial-setup" title="Permalink to this heading">#</a></h2>
<p>If you chose Option 2 with Docker in Install Guide, you can skip this part and follow Docker instruction below. Please be aware you will need to download models every time in Docker container.
To avoid this you can follow Tutorial Setup for Docker to download models on host and mount them inside Docker container.</p>
<ol class="arabic">
<li><p>Install Intel® Deep Learning Streamer (Intel® DL Streamer) Pipeline Framework by following the <a class="reference internal" href="install/install_guide_ubuntu.html"><span class="doc">Install-Guide</span></a>.</p></li>
<li><p>Set the environment variables:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span><span class="nb">source</span><span class="w"> </span>/opt/intel/openvino_2024/setupvars.sh
<span class="nb">source</span><span class="w"> </span>/opt/intel/dlstreamer/gstreamer/setupvars.sh
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>You must set the environment variables each time you open a new shell unless you added the variables to the <code class="docutils literal notranslate"><span class="pre">.bashrc</span></code> file. See
<a class="reference external" href="https://docs.openvino.ai/latest/openvino_docs_install_guides_installing_openvino_from_archive_linux.html#step-2-configure-the-environment">Set the environment variables</a>.</p>
</div>
</li>
<li><p>Download the models from <a class="reference external" href="https://github.com/openvinotoolkit/open_model_zoo">Open Model Zoo</a></p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>python3<span class="w"> </span>-m<span class="w"> </span>pip<span class="w"> </span>install<span class="w"> </span>--upgrade<span class="w"> </span>pip
python3<span class="w"> </span>-m<span class="w"> </span>pip<span class="w"> </span>install<span class="w"> </span>openvino-dev<span class="o">[</span>onnx,tensorflow,pytorch<span class="o">]</span>
/opt/intel/dlstreamer/samples/download_models.sh
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Make sure your environment variable $PATH includes ‘$HOME/.local/bin’ .</p>
</div>
</li>
<li><p>Export the <em>model</em> and <em>model_proc</em> files for detection and classification:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span><span class="w"> </span><span class="nv">DETECTION_MODEL</span><span class="o">=</span><span class="si">${</span><span class="nv">MODELS_PATH</span><span class="si">}</span>/intel/person-vehicle-bike-detection-2004/FP32/person-vehicle-bike-detection-2004.xml
<span class="nb">export</span><span class="w"> </span><span class="nv">DETECTION_MODEL_PROC</span><span class="o">=</span>/opt/intel/dlstreamer/samples/gstreamer/model_proc/intel/person-vehicle-bike-detection-2004.json
<span class="nb">export</span><span class="w"> </span><span class="nv">VEHICLE_CLASSIFICATION_MODEL</span><span class="o">=</span><span class="si">${</span><span class="nv">MODELS_PATH</span><span class="si">}</span>/intel/vehicle-attributes-recognition-barrier-0039/FP32/vehicle-attributes-recognition-barrier-0039.xml
<span class="nb">export</span><span class="w"> </span><span class="nv">VEHICLE_CLASSIFICATION_MODEL_PROC</span><span class="o">=</span>/opt/intel/dlstreamer/samples/gstreamer/model_proc/intel/vehicle-attributes-recognition-barrier-0039.json
</pre></div>
</div>
<p>If you want to use your own models, you need to first convert them in
the IR (Intermediate Representation) format. For detailed
instructions to convert models, <a class="reference external" href="https://docs.openvino.ai/latest/openvino_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_YOLO_From_Tensorflow.html">look
here</a></p>
</li>
<li><p>Export the video file path:</p>
<p>You may download a sample video from the
<a class="reference external" href="https://github.com/intel-iot-devkit/sample-videos/raw/master/person-bicycle-car-detection.mp4">here</a>.
If you provide your own video file as an input, please make sure that
it is in h264 or mp4 format. You can also download and use freely
licensed content from the websites such as Pexels*. Any video with
cars, or pedestrians can be used with the exercise.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span><span class="c1"># This tutorial uses ~/path/to/video as the video path</span>
<span class="c1"># and FILENAME as the placeholder for a video file name.</span>
<span class="c1"># Change this information to fit your setup.</span>
<span class="nb">export</span><span class="w"> </span><span class="nv">VIDEO_EXAMPLE</span><span class="o">=</span>~/path/to/video/FILENAME
</pre></div>
</div>
</li>
</ol>
</section>
<section id="tutorial-setup-for-docker">
<span id="object-detection"></span><h2>Tutorial Setup for Docker<a class="headerlink" href="#tutorial-setup-for-docker" title="Permalink to this heading">#</a></h2>
<ol class="arabic">
<li><p>Install pip,onnx and tensorflow:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>sudo<span class="w"> </span>apt-get<span class="w"> </span>install<span class="w"> </span>python3-pip
python3<span class="w"> </span>-m<span class="w"> </span>pip<span class="w"> </span>install<span class="w"> </span>openvino-dev<span class="o">[</span>onnx,tensorflow,pytorch<span class="o">]</span>
</pre></div>
</div>
</li>
<li><p>Clone DLStreamer repository:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>mkdir<span class="w"> </span>-p<span class="w"> </span>~/intel
git<span class="w"> </span>clone<span class="w"> </span>--recursive<span class="w"> </span>https://github.com/dlstreamer/dlstreamer.git<span class="w"> </span>~/intel/dlstreamer_gst
</pre></div>
</div>
</li>
<li><p>Export <code class="docutils literal notranslate"><span class="pre">MODELS_PATH</span></code> where models will be dowloaded, for example:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span><span class="w"> </span><span class="nv">MODELS_PATH</span><span class="o">=</span>/home/<span class="nv">$USER</span>/models
</pre></div>
</div>
</li>
<li><p>Make sure your environmental variable <code class="docutils literal notranslate"><span class="pre">$PATH</span></code> includes <code class="docutils literal notranslate"><span class="pre">/home/user/.local/bin</span></code>:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span><span class="w"> </span><span class="nv">PATH</span><span class="o">=</span><span class="s2">&quot;</span><span class="nv">$PATH</span><span class="s2">:/home/</span><span class="nv">$USER</span><span class="s2">/.local/bin&quot;</span>
</pre></div>
</div>
</li>
<li><p>Download models:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>~/intel/dlstreamer_gst/samples
./download_models.sh
</pre></div>
</div>
</li>
<li><p>Mount the models directory into the container using <code class="docutils literal notranslate"><span class="pre">-v</span></code> or <code class="docutils literal notranslate"><span class="pre">--volume</span></code> parameter in <code class="docutils literal notranslate"><span class="pre">docker</span> <span class="pre">run</span></code> command.
Make sure your mounting parameter is specified as <code class="docutils literal notranslate"><span class="pre">-v</span> <span class="pre">&lt;path_on_host&gt;:&lt;path_in_the_container&gt;</span></code>:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>docker<span class="w"> </span>run<span class="w"> </span>-v<span class="w"> </span>/home/<span class="nv">$USER</span>/models:/home/dlstreamer/intel/dl_streamer/models<span class="w">  </span>&lt;other<span class="w"> </span>args&gt;
</pre></div>
</div>
<p>To run the Docker image on a GPU device:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>docker<span class="w"> </span>run<span class="w"> </span>-it<span class="w"> </span>--device<span class="w"> </span>/dev/dri<span class="w"> </span>--group-add<span class="o">=</span><span class="k">$(</span>stat<span class="w"> </span>-c<span class="w"> </span><span class="s2">&quot;%g&quot;</span><span class="w"> </span>/dev/dri/render*<span class="k">)</span><span class="w"> </span>-v<span class="w"> </span>/home/<span class="nv">$USER</span>/models:/home/dlstreamer/intel/dl_streamer/models<span class="w"> </span>dlstreamer:latest
</pre></div>
</div>
<p>To run the Docker image on an NPU device:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>docker<span class="w"> </span>run<span class="w"> </span>-it<span class="w"> </span>--device<span class="w"> </span>/dev/dri<span class="w"> </span>--device<span class="w"> </span>/dev/accel/accel0<span class="w"> </span>--group-add<span class="o">=</span><span class="k">$(</span>stat<span class="w"> </span>-c<span class="w"> </span><span class="s2">&quot;%g&quot;</span><span class="w"> </span>/dev/dri/render*<span class="k">)</span><span class="w"> </span>-v<span class="w"> </span>/home/<span class="nv">$USER</span>/models:/home/dlstreamer/intel/dl_streamer/models<span class="w"> </span>dlstreamer:latest
</pre></div>
</div>
</li>
<li><p>Export the <em>model</em> and <em>model_proc</em> files for detection and classification:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span><span class="w"> </span><span class="nv">DETECTION_MODEL</span><span class="o">=</span><span class="si">${</span><span class="nv">MODELS_PATH</span><span class="si">}</span>/intel/person-vehicle-bike-detection-2004/FP32/person-vehicle-bike-detection-2004.xml
<span class="nb">export</span><span class="w"> </span><span class="nv">DETECTION_MODEL_PROC</span><span class="o">=</span>/opt/intel/dlstreamer/samples/gstreamer/model_proc/intel/person-vehicle-bike-detection-2004.json
<span class="nb">export</span><span class="w"> </span><span class="nv">VEHICLE_CLASSIFICATION_MODEL</span><span class="o">=</span><span class="si">${</span><span class="nv">MODELS_PATH</span><span class="si">}</span>/intel/vehicle-attributes-recognition-barrier-0039/FP32/vehicle-attributes-recognition-barrier-0039.xml
<span class="nb">export</span><span class="w"> </span><span class="nv">VEHICLE_CLASSIFICATION_MODEL_PROC</span><span class="o">=</span>/opt/intel/dlstreamer/samples/gstreamer/model_proc/intel/vehicle-attributes-recognition-barrier-0039.json
</pre></div>
</div>
<p>If you want to use your own models, you need to first convert them in
the IR (Intermediate Representation) format. For detailed
instructions to convert models, <a class="reference external" href="https://docs.openvino.ai/latest/openvino_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_YOLO_From_Tensorflow.html">look
here</a></p>
</li>
<li><p>Export the video file path:</p>
<p>You may download a sample video from the
<a class="reference external" href="https://github.com/intel-iot-devkit/sample-videos/raw/master/person-bicycle-car-detection.mp4">here</a>.
If you provide your own video file as an input, please make sure that
it is in h264 or mp4 format. You can also download and use freely
licensed content from the websites such as Pexels*. Any video with
cars, or pedestrians can be used with the exercise.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span><span class="c1"># This tutorial uses ~/path/to/video as the video path</span>
<span class="c1"># and FILENAME as the placeholder for a video file name.</span>
<span class="c1"># Change this information to fit your setup.</span>
<span class="nb">export</span><span class="w"> </span><span class="nv">VIDEO_EXAMPLE</span><span class="o">=</span>~/path/to/video/FILENAME
</pre></div>
</div>
</li>
</ol>
</section>
<section id="exercise-1-build-object-detection-pipeline">
<span id="id1"></span><h2>Exercise 1 - Build object detection pipeline<a class="headerlink" href="#exercise-1-build-object-detection-pipeline" title="Permalink to this heading">#</a></h2>
<p>This exercise helps you create a GStreamer pipeline that will perform
object detection using <em>gvadetect</em> element and Intermediate
Representation (IR) formatted object detection model. It provides two
optional add-ons to show you how to use video from a web camera stream
and an RTSP URI.</p>
<p>This exercise introduces you to using the following Pipeline Framework elements:</p>
<ul class="simple">
<li><p>gvadetect</p></li>
<li><p>gvawatermark</p></li>
</ul>
<section id="pipeline">
<h3>Pipeline<a class="headerlink" href="#pipeline" title="Permalink to this heading">#</a></h3>
<p>We will create a pipeline to detect people and vehicles in a video. The
pipeline will accept a video file input, decode it and run vehicle
detection. It will overlay the bounding boxes for detected vehicles on
the video frame and render the video to local device.</p>
<p>Run the below pipeline at the command prompt and review the output:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>gst-launch-1.0<span class="w"> </span><span class="se">\</span>
filesrc<span class="w"> </span><span class="nv">location</span><span class="o">=</span><span class="si">${</span><span class="nv">VIDEO_EXAMPLE</span><span class="si">}</span><span class="w"> </span>!<span class="w"> </span>decodebin<span class="w"> </span>!<span class="w"> </span><span class="se">\</span>
gvadetect<span class="w"> </span><span class="nv">model</span><span class="o">=</span><span class="si">${</span><span class="nv">DETECTION_MODEL</span><span class="si">}</span><span class="w"> </span><span class="nv">model_proc</span><span class="o">=</span><span class="si">${</span><span class="nv">DETECTION_MODEL_PROC</span><span class="si">}</span><span class="w"> </span><span class="nv">device</span><span class="o">=</span>CPU<span class="w"> </span>!<span class="w"> </span>queue<span class="w"> </span>!<span class="w"> </span><span class="se">\</span>
gvawatermark<span class="w"> </span>!<span class="w"> </span>videoconvert<span class="w"> </span>!<span class="w"> </span>fpsdisplaysink<span class="w"> </span>video-sink<span class="o">=</span>xvimagesink<span class="w"> </span><span class="nv">sync</span><span class="o">=</span><span class="nb">false</span>
</pre></div>
</div>
<p><strong>Expected output</strong>: You will see your video overlaid by bounding boxes
around persons, vehicles, and bikes.</p>
<p>In addition to the elements described in the first two section, the
pipeline uses
<a class="reference external" href="https://gstreamer.freedesktop.org/documentation/debugutilsbad/fpsdisplaysink.html?gi-language=c">`fpsdisplaysink`</a>
to display the average FPS of the pipeline.</p>
<p>You’re done building and running this pipeline. To expand on this
exercise, use one or both add-ons to this exercise to select different
video sources. If the add-ons don’t suit you, jump ahead to start
<a class="reference external" href="#object-classification">Exercise 2</a>.</p>
<section id="pipeline-with-a-web-camera-video-stream-input-first-optional-add-on-to-exercise-1">
<h4>Pipeline with a Web Camera Video Stream Input (First optional add-on to Exercise 1)<a class="headerlink" href="#pipeline-with-a-web-camera-video-stream-input-first-optional-add-on-to-exercise-1" title="Permalink to this heading">#</a></h4>
<p>GStreamer supports connected video devices, like web cameras, which
means you use a web camera to perform real-time inference.</p>
<p>In order to use web camera as an input, we will replace the <em>filesrc</em>
element in the object detection pipeline with
<a class="reference external" href="https://gstreamer.freedesktop.org/documentation/video4linux2/v4l2src.html?gi-language=c">`v4l2src`</a>
element, that is used for capturing video from webcams. Before running
the below updated pipeline, check the web camera path and update it in
the pipeline. The web camera stream is usually in the <em>/dev/</em>
directory.</p>
<p>Object detection pipeline using Web camera:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span><span class="c1"># Change &lt;path-to-device&gt; below to your web camera device path</span>
gst-launch-1.0<span class="w"> </span><span class="se">\</span>
v4l2src<span class="w"> </span><span class="nv">device</span><span class="o">=</span>&lt;path-to-device&gt;<span class="w"> </span>!<span class="w"> </span>decodebin<span class="w"> </span>!<span class="w"> </span><span class="se">\</span>
gvadetect<span class="w"> </span><span class="nv">model</span><span class="o">=</span><span class="si">${</span><span class="nv">DETECTION_MODEL</span><span class="si">}</span><span class="w"> </span><span class="nv">model_proc</span><span class="o">=</span><span class="si">${</span><span class="nv">DETECTION_MODEL_PROC</span><span class="si">}</span><span class="w"> </span><span class="nv">device</span><span class="o">=</span>CPU<span class="w"> </span>!<span class="w"> </span>queue<span class="w"> </span>!<span class="w"> </span><span class="se">\</span>
gvawatermark<span class="w"> </span>!<span class="w"> </span>videoconvert<span class="w"> </span>!<span class="w"> </span>fpsdisplaysink<span class="w"> </span>video-sink<span class="o">=</span>xvimagesink<span class="w"> </span><span class="nv">sync</span><span class="o">=</span><span class="nb">false</span>
</pre></div>
</div>
</section>
<section id="pipeline-with-an-rtsp-input-second-optional-add-on-to-exercise-1">
<h4>Pipeline with an RTSP Input (Second optional add-on to Exercise 1)<a class="headerlink" href="#pipeline-with-an-rtsp-input-second-optional-add-on-to-exercise-1" title="Permalink to this heading">#</a></h4>
<p>In order to use RTSP source as an input, we will replace the <em>filesrc</em>
element in the object detection pipeline with
<a class="reference external" href="https://gstreamer.freedesktop.org/documentation/playback/urisourcebin.html?gi-language=c">`urisourcebin`</a>
to access URIs. Before running the below updated pipeline, replace ‘&lt;RTSP_uri&gt;’
with your RTSP URI and verify it before running the command.</p>
<p>Object detection pipeline using RTSP URI:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span><span class="c1"># Change &lt;RTSP_uri&gt; below to your RTSP URL</span>
gst-launch-1.0<span class="w"> </span><span class="se">\</span>
urisourcebin<span class="w"> </span><span class="nv">uri</span><span class="o">=</span>&lt;RTSP_uri&gt;<span class="w"> </span>!<span class="w"> </span>decodebin<span class="w"> </span>!<span class="w"> </span><span class="se">\</span>
gvadetect<span class="w"> </span><span class="nv">model</span><span class="o">=</span><span class="si">${</span><span class="nv">DETECTION_MODEL</span><span class="si">}</span><span class="w"> </span><span class="nv">model_proc</span><span class="o">=</span><span class="si">${</span><span class="nv">DETECTION_MODEL_PROC</span><span class="si">}</span><span class="w"> </span><span class="nv">device</span><span class="o">=</span>CPU<span class="w"> </span>!<span class="w"> </span>queue<span class="w"> </span>!<span class="w"> </span><span class="se">\</span>
gvawatermark<span class="w"> </span>!<span class="w"> </span>videoconvert<span class="w"> </span>!<span class="w"> </span>fpsdisplaysink<span class="w"> </span>video-sink<span class="o">=</span>xvimagesink<span class="w"> </span><span class="nv">sync</span><span class="o">=</span><span class="nb">false</span>
</pre></div>
</div>
</section>
</section>
</section>
<section id="exercise-2-build-object-classification-pipeline">
<span id="object-classification"></span><h2>Exercise 2: Build object classification pipeline<a class="headerlink" href="#exercise-2-build-object-classification-pipeline" title="Permalink to this heading">#</a></h2>
<p>This exercise helps you create a GStreamer pipeline that will perform
object classification on the Regions of Interest (ROIs) detected by <em>gvadetect</em> using
<em>gvaclassify</em> element and Intermediate Representation (IR) formatted
object classification model.</p>
<p>This exercise uses the following Pipeline Framework elements:</p>
<ul class="simple">
<li><p>gvadetect</p></li>
<li><p>gvaclassify</p></li>
<li><p>gvawatermark</p></li>
</ul>
<section id="pipeline-1">
<span id="id2"></span><h3>Pipeline<a class="headerlink" href="#pipeline-1" title="Permalink to this heading">#</a></h3>
<p>We will create a pipeline to detect people and vehicles in a video and
classify the detected people and vehicle to provide additional
attributes.</p>
<p>Run the below pipeline at the command prompt and review the output:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>gst-launch-1.0<span class="w"> </span><span class="se">\</span>
filesrc<span class="w"> </span><span class="nv">location</span><span class="o">=</span><span class="si">${</span><span class="nv">VIDEO_EXAMPLE</span><span class="si">}</span><span class="w"> </span>!<span class="w"> </span>decodebin<span class="w"> </span>!<span class="w"> </span><span class="se">\</span>
gvadetect<span class="w"> </span><span class="nv">model</span><span class="o">=</span><span class="si">${</span><span class="nv">DETECTION_MODEL</span><span class="si">}</span><span class="w"> </span><span class="nv">model_proc</span><span class="o">=</span><span class="si">${</span><span class="nv">DETECTION_MODEL_PROC</span><span class="si">}</span><span class="w"> </span><span class="nv">device</span><span class="o">=</span>CPU<span class="w"> </span>!<span class="w"> </span>queue<span class="w"> </span>!<span class="w"> </span><span class="se">\</span>
gvaclassify<span class="w"> </span><span class="nv">model</span><span class="o">=</span><span class="si">${</span><span class="nv">VEHICLE_CLASSIFICATION_MODEL</span><span class="si">}</span><span class="w"> </span>model-proc<span class="o">=</span><span class="si">${</span><span class="nv">VEHICLE_CLASSIFICATION_MODEL_PROC</span><span class="si">}</span><span class="w"> </span><span class="nv">device</span><span class="o">=</span>CPU<span class="w"> </span>object-class<span class="o">=</span>vehicle<span class="w"> </span>!<span class="w"> </span>queue<span class="w"> </span>!<span class="w"> </span><span class="se">\</span>
gvawatermark<span class="w"> </span>!<span class="w"> </span>videoconvert<span class="w"> </span>!<span class="w"> </span>fpsdisplaysink<span class="w"> </span>video-sink<span class="o">=</span>xvimagesink<span class="w"> </span><span class="nv">sync</span><span class="o">=</span><span class="nb">false</span>
</pre></div>
</div>
<p><strong>Expected output</strong>: Persons, vehicles, and bikes are bound by colored
boxes, and detection results as well as classification attributes such
as vehicle type and color are displayed as video overlays.</p>
<p>In the above pipeline:</p>
<ol class="arabic simple">
<li><p><em>gvadetect</em> detects the ROIs in the video and outputs ROIs with the
appropriate attributes (person, vehicle, bike) according to its
model-proc.</p></li>
<li><p><em>gvadetect</em> ROIs are used as inputs for the <em>gvaclassify</em> model.</p></li>
<li><p><em>gvaclassify</em> classifies the ROIs and outputs additional attributes
according to model-proc:</p>
<ul class="simple">
<li><p><em>object-class</em> tells <em>gvalcassify</em> which ROIs to classify.</p></li>
<li><p><em>object-class=vehicle</em> classifies ROIs with ‘vehicle’ attribute only.</p></li>
</ul>
</li>
<li><p><em>gvawatermark</em> displays the ROIs and their attributes.</p></li>
</ol>
<p>See <a class="reference external" href="https://github.com/dlstreamer/dlstreamer/tree/master/samples/gstreamer/model_proc">model-proc</a>
for the model-procs and its input and output specifications.</p>
</section>
</section>
<section id="exercise-3-use-object-tracking-to-improve-performance">
<span id="object-tracking"></span><h2>Exercise 3: Use object tracking to improve performance<a class="headerlink" href="#exercise-3-use-object-tracking-to-improve-performance" title="Permalink to this heading">#</a></h2>
<p>This exercise helps you create a GStreamer pipeline that will use object
tracking for reducing the frequency of object detection and
classification, thereby increasing the throughput, using <em>gvatrack</em>.</p>
<p>This exercise uses the following Pipeline Framework elements:</p>
<ul class="simple">
<li><p>gvadetect</p></li>
<li><p>gvaclassify</p></li>
<li><p>gvatrack</p></li>
<li><p>gvawatermark</p></li>
</ul>
<section id="pipeline-2">
<span id="id3"></span><h3>Pipeline<a class="headerlink" href="#pipeline-2" title="Permalink to this heading">#</a></h3>
<p>We will use the same pipeline as in exercise 2, for detecting and
classifying vehicle and people. We will add <em>gvatrack</em> element after
<em>gvadetect</em> and before <em>gvaclassify</em> to track objects. <em>gvatrack</em>
will assign object IDs and provide updated ROIs in between detections.
We will also specify parameters of <em>gvadetect</em> and <em>gvaclassify</em>
elements to reduce frequency of detection and classification.</p>
<p>Run the below pipeline at the command prompt and review the output:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>gst-launch-1.0<span class="w"> </span><span class="se">\</span>
filesrc<span class="w"> </span><span class="nv">location</span><span class="o">=</span><span class="si">${</span><span class="nv">VIDEO_EXAMPLE</span><span class="si">}</span><span class="w"> </span>!<span class="w"> </span>decodebin<span class="w"> </span>!<span class="w"> </span><span class="se">\</span>
gvadetect<span class="w"> </span><span class="nv">model</span><span class="o">=</span><span class="si">${</span><span class="nv">DETECTION_MODEL</span><span class="si">}</span><span class="w"> </span><span class="nv">model_proc</span><span class="o">=</span><span class="si">${</span><span class="nv">DETECTION_MODEL_PROC</span><span class="si">}</span><span class="w"> </span><span class="nv">device</span><span class="o">=</span>CPU<span class="w"> </span>inference-interval<span class="o">=</span><span class="m">10</span><span class="w"> </span>!<span class="w"> </span>queue<span class="w"> </span>!<span class="w"> </span><span class="se">\</span>
gvatrack<span class="w"> </span>tracking-type<span class="o">=</span>short-term-imageless<span class="w"> </span>!<span class="w"> </span>queue<span class="w"> </span>!<span class="w"> </span><span class="se">\</span>
gvaclassify<span class="w"> </span><span class="nv">model</span><span class="o">=</span><span class="si">${</span><span class="nv">VEHICLE_CLASSIFICATION_MODEL</span><span class="si">}</span><span class="w"> </span>model-proc<span class="o">=</span><span class="si">${</span><span class="nv">VEHICLE_CLASSIFICATION_MODEL_PROC</span><span class="si">}</span><span class="w"> </span><span class="nv">device</span><span class="o">=</span>CPU<span class="w"> </span>object-class<span class="o">=</span>vehicle<span class="w"> </span>reclassify-interval<span class="o">=</span><span class="m">10</span><span class="w"> </span>!<span class="w"> </span>queue<span class="w"> </span>!<span class="w"> </span><span class="se">\</span>
gvawatermark<span class="w"> </span>!<span class="w"> </span>videoconvert<span class="w"> </span>!<span class="w"> </span>fpsdisplaysink<span class="w"> </span>video-sink<span class="o">=</span>xvimagesink<span class="w"> </span><span class="nv">sync</span><span class="o">=</span><span class="nb">false</span>
</pre></div>
</div>
<p><strong>Expected output</strong>: Persons, vehicles, and bikes are bound by colored
boxes, and detection results as well as classification attributes such
as vehicle type and color are displayed as video overlays, same as
exercise 2. However, notice the increase in the FPS of the pipeline.</p>
<p>In the above pipeline:</p>
<ol class="arabic simple">
<li><p><em>gvadetect</em> detects the ROIs in the video and outputs ROIs with the
appropriate attributes (person, vehicle, bike) according to its
model-proc on every 10th frame, due to <em>inference-interval=10</em>.</p></li>
<li><p><em>gvatrack</em> tracks each object detected by <em>gvadetect</em>.</p></li>
<li><p><em>gvadetect</em> ROIs are used as inputs for the <em>gvaclassify</em> model.</p></li>
<li><p><em>gvaclassify</em> classifies the ROIs and outputs additional attributes
according to model-proc, but skips classification for already
classified objects for 10 frames, using tracking information from
<em>gvatrack</em> to determine whether to classify an object:</p>
<ul class="simple">
<li><p><em>object-class</em> tells <em>gvaclassify</em> which ROIs to classify.</p></li>
<li><p><em>object-class=vehicle</em> classifies ROIs that have the ‘vehicle’ attribute.</p></li>
<li><p><em>reclassify-interval</em> determines how often to reclassify tracked objects. Only valid when used in conjunction with gvatrack.</p></li>
</ul>
</li>
<li><p><em>gvawatermark</em> displays the ROIs and their attributes.</p></li>
</ol>
<p>You’re done building and running this pipeline. The next exercise shows
you how to publish your results to a <em>.json</em>.</p>
</section>
</section>
<section id="exercise-4-publish-inference-results">
<span id="result-publishing"></span><h2>Exercise 4: Publish Inference Results<a class="headerlink" href="#exercise-4-publish-inference-results" title="Permalink to this heading">#</a></h2>
<p>This exercise extends the pipeline to publish your detection and
classification results to a <em>.json</em> file from a GStreamer pipeline.</p>
<p>This exercise uses the following Pipeline Framework elements:</p>
<ul class="simple">
<li><p>gvadetect</p></li>
<li><p>gvaclassify</p></li>
<li><p>gvametaconvert</p></li>
<li><p>gvametapublish</p></li>
</ul>
<section id="setup">
<h3>Setup<a class="headerlink" href="#setup" title="Permalink to this heading">#</a></h3>
<p>One additional setup step is required for this exercise, to export the
output file path:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span><span class="c1"># Replace &lt;path-to-FILENAME&gt; with path to your file before running the below command.</span>
<span class="nb">export</span><span class="w"> </span><span class="nv">OUTFILE</span><span class="o">=</span>&lt;path-to-FILENAME&gt;
</pre></div>
</div>
</section>
<section id="pipeline-3">
<span id="id4"></span><h3>Pipeline<a class="headerlink" href="#pipeline-3" title="Permalink to this heading">#</a></h3>
<p>We will use the same pipeline as in exercise 2 for detecting and
classifying vehicle and people. However, instead of overlaying the
results and rendering them to a screen, we will send them to a file in
JSON format.</p>
<p>Run the below pipeline at the command prompt and review the output:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>gst-launch-1.0<span class="w"> </span><span class="se">\</span>
filesrc<span class="w"> </span><span class="nv">location</span><span class="o">=</span><span class="si">${</span><span class="nv">VIDEO_EXAMPLE</span><span class="si">}</span><span class="w"> </span>!<span class="w"> </span>decodebin<span class="w"> </span>!<span class="w"> </span><span class="se">\</span>
gvadetect<span class="w"> </span><span class="nv">model</span><span class="o">=</span><span class="si">${</span><span class="nv">DETECTION_MODEL</span><span class="si">}</span><span class="w"> </span><span class="nv">model_proc</span><span class="o">=</span><span class="si">${</span><span class="nv">DETECTION_MODEL_PROC</span><span class="si">}</span><span class="w"> </span><span class="nv">device</span><span class="o">=</span>CPU<span class="w"> </span>!<span class="w"> </span>queue<span class="w"> </span>!<span class="w"> </span><span class="se">\</span>
gvaclassify<span class="w"> </span><span class="nv">model</span><span class="o">=</span><span class="si">${</span><span class="nv">VEHICLE_CLASSIFICATION_MODEL</span><span class="si">}</span><span class="w"> </span>model-proc<span class="o">=</span><span class="si">${</span><span class="nv">VEHICLE_CLASSIFICATION_MODEL_PROC</span><span class="si">}</span><span class="w"> </span><span class="nv">device</span><span class="o">=</span>CPU<span class="w"> </span>object-class<span class="o">=</span>vehicle<span class="w"> </span>!<span class="w"> </span>queue<span class="w"> </span>!<span class="w"> </span><span class="se">\</span>
gvametaconvert<span class="w"> </span><span class="nv">format</span><span class="o">=</span>json<span class="w"> </span>!<span class="w"> </span><span class="se">\</span>
gvametapublish<span class="w"> </span><span class="nv">method</span><span class="o">=</span>file<span class="w"> </span>file-path<span class="o">=</span><span class="si">${</span><span class="nv">OUTFILE</span><span class="si">}</span><span class="w"> </span>!<span class="w"> </span><span class="se">\</span>
fakesink
</pre></div>
</div>
<p><strong>Expected output</strong>: After the pipeline completes, a JSON file of the
inference results is available. Review the JSON file.</p>
<p>In the above pipeline:</p>
<ul class="simple">
<li><p><em>gvametaconvert</em> uses the optional parameter <em>format=json</em> to convert inferenced data to <em>GstGVAJSONMeta</em>.</p></li>
<li><p><em>GstGVAJSONMeta</em> is a custom data structure that represents JSON metadata.</p></li>
<li><p><em>gvametapublish</em> uses the optional parameter <em>method=file</em> to publish inference results to a file.</p></li>
<li><p><em>filepath=${OUTFILE}</em> is a JSON file to which the inference results are published.</p></li>
</ul>
<p>For publishing the results to MQTT or Kafka, please refer to the
<a class="reference external" href="https://github.com/dlstreamer/dlstreamer/tree/master/samples/gstreamer/gst_launch/metapublish">metapublish samples</a>.</p>
<p>You have completed this tutorial. Now, start creating your video
analytics pipeline with Intel® DL Streamer Pipeline Framework!</p>
</section>
</section>
<section id="next-steps">
<h2>Next Steps<a class="headerlink" href="#next-steps" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/dlstreamer/dlstreamer/blob/master/samples/gstreamer/README.md">Samples overview</a></p></li>
<li><p><a class="reference internal" href="../elements/elements.html"><span class="doc">Elements</span></a></p></li>
<li><p><a class="reference internal" href="../dev_guide/how_to_create_model_proc_file.html"><span class="doc">How to Create Model-proc File</span></a></p></li>
</ul>
<hr class="docutils" />
<blockquote>
<div><p><strong>*</strong> <em>Other names and brands may be claimed as the property of others.</em></p>
</div></blockquote>
</section>
</section>


                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="install/uninstall_guide_ubuntu.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Uninstall Guide Ubuntu</p>
      </div>
    </a>
    <a class="right-next"
       href="flex_series/quick_start_guide.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Quick Start Guide for Media Analytics on Intel® Data Center GPU Flex Series</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#about-gstreamer">About GStreamer</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pipelines">Pipelines</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#elements">Elements</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#properties">Properties</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction-to-intel-deep-learning-streamer-intel-dl-streamer-pipeline-framework">Introduction to Intel® Deep Learning Streamer (Intel® DL Streamer) Pipeline Framework</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tutorial-setup">Tutorial Setup</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tutorial-setup-for-docker">Tutorial Setup for Docker</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-1-build-object-detection-pipeline">Exercise 1 - Build object detection pipeline</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pipeline">Pipeline</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#pipeline-with-a-web-camera-video-stream-input-first-optional-add-on-to-exercise-1">Pipeline with a Web Camera Video Stream Input (First optional add-on to Exercise 1)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#pipeline-with-an-rtsp-input-second-optional-add-on-to-exercise-1">Pipeline with an RTSP Input (Second optional add-on to Exercise 1)</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-2-build-object-classification-pipeline">Exercise 2: Build object classification pipeline</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pipeline-1">Pipeline</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-3-use-object-tracking-to-improve-performance">Exercise 3: Use object tracking to improve performance</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pipeline-2">Pipeline</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-4-publish-inference-results">Exercise 4: Publish Inference Results</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#setup">Setup</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pipeline-3">Pipeline</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#next-steps">Next Steps</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Intel Corporation
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2024, Intel Corporation.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=5b4479735964841361fd"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>