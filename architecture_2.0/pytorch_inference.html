
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

    <title>PyTorch tensor inference [Preview] &#8212; Intel® Deep Learning Streamer (Intel® DL Streamer)  documentation</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../_static/doxyrest-pygments.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script src="../_static/target-highlight.js"></script>
    <script src="https://unpkg.com/mermaid@9.4.0/dist/mermaid.min.js"></script>
    <script>mermaid.initialize({startOnLoad:true});</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Elements 2.0" href="elements_list.html" />
    <link rel="prev" title="③ Python Bindings" href="python_bindings.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
      
      
      <h1 class="site-logo" id="site-title">Intel® Deep Learning Streamer (Intel® DL Streamer)  documentation</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../get_started/get_started_index.html">
   Get Started
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../get_started/hardware_requirements.html">
     Hardware Requirements
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../get_started/install/install_guide_index.html">
     Install Guide
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
    <label for="toctree-checkbox-2">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../get_started/install/install_guide_ubuntu.html">
       Install Guide Ubuntu
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../get_started/install/uninstall_guide_ubuntu.html">
       Uninstall Guide Ubuntu
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../get_started/tutorial.html">
     Tutorial
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../get_started/flex_series/quick_start_guide.html">
     Quick Start Guide for Media Analytics on Intel® Data Center GPU Flex Series
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference external" href="https://github.com/dlstreamer/dlstreamer/blob/master/samples/gstreamer/README.md">
     Samples
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../dev_guide/dev_guide_index.html">
   Developer Guide
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../dev_guide/metadata.html">
     Metadata
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../dev_guide/model_preparation.html">
     Model Preparation
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
    <label for="toctree-checkbox-4">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../dev_guide/yolov5_model_preparation.html">
       Yolov5 Model Preparation Example
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../dev_guide/model_proc_file.html">
     Model-proc File
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../dev_guide/how_to_create_model_proc_file.html">
     How to Create Model-proc File
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../dev_guide/python_bindings.html">
     Python Bindings
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../dev_guide/custom_processing.html">
     Custom Processing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../dev_guide/object_tracking.html">
     Object Tracking
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../dev_guide/gpu_device_selection.html">
     GPU device selection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../dev_guide/profiling.html">
     Profiling with Intel VTune™
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../dev_guide/converting_deepstream_to_dlstreamer.html">
     Converting NVIDIA DeepStream Pipelines to Intel® Deep Learning Streamer (Intel® DL Streamer) Pipeline Framework
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../dev_guide/how_to_contribute.html">
     How to Contribute
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
    <label for="toctree-checkbox-5">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../dev_guide/coding_style.html">
       Coding Style
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../elements/elements.html">
   Elements
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../elements/gvadetect.html">
     gvadetect
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../elements/gvaclassify.html">
     gvaclassify
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../elements/gvainference.html">
     gvainference
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../elements/gvaaudiodetect.html">
     gvaaudiodetect
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../elements/gvatrack.html">
     gvatrack
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../elements/gvametaconvert.html">
     gvametaconvert
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../elements/gvametapublish.html">
     gvametapublish
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../elements/gvametaaggregate.html">
     gvametaaggregate
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../elements/gvapython.html">
     gvapython
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../elements/gvawatermark.html">
     gvawatermark
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../elements/gvafpscounter.html">
     gvafpscounter
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../supported_models.html">
   Supported Models
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../api_ref/api_reference.html">
   API Reference
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../api_ref/page_index.html">
     Intel® Deep Learning Streamer (Intel® DL Streamer) API reference
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../api_ref/global.html">
     Global Namespace
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
    <label for="toctree-checkbox-8">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../api_ref/namespace_GVA.html">
       namespace GVA
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
      <label for="toctree-checkbox-9">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../api_ref/struct_GVA_Rect.html">
         template struct GVA::Rect
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../api_ref/struct_GVA_Segment.html">
         template struct GVA::Segment
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../api_ref/class_GVA_AudioEvent.html">
         class GVA::AudioEvent
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../api_ref/class_GVA_AudioFrame.html">
         class GVA::AudioFrame
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../api_ref/class_GVA_RegionOfInterest.html">
         class GVA::RegionOfInterest
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../api_ref/class_GVA_Tensor.html">
         class GVA::Tensor
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../api_ref/class_GVA_VideoFrame.html">
         class GVA::VideoFrame
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../api_ref/namespace_gstgva.html">
       namespace gstgva
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
      <label for="toctree-checkbox-10">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../api_ref/namespace_gstgva_region_of_interest.html">
         namespace gstgva::region_of_interest
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../api_ref/namespace_gstgva_tensor.html">
         namespace gstgva::tensor
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../api_ref/namespace_gstgva_video_frame.html">
         namespace gstgva::video_frame
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../api_ref/enum_GVALayout.html">
       enum GVALayout
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../api_ref/enum_GVAPrecision.html">
       enum GVAPrecision
      </a>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../api_ref/struct_GstGVAAudioEventMeta.html">
       struct GstGVAAudioEventMeta
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
      <label for="toctree-checkbox-11">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul class="simple">
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../api_ref/struct__GstGVAJSONMeta.html">
       struct _GstGVAJSONMeta
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
      <label for="toctree-checkbox-12">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul class="simple">
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../api_ref/struct__GstGVATensorMeta.html">
       struct _GstGVATensorMeta
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
      <label for="toctree-checkbox-13">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul class="simple">
      </ul>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="architecture_2.0.html">
   Architecture 2.0 [Preview]
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/>
  <label for="toctree-checkbox-14">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="migration_guide.html">
     Migration to 2.0
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="cpp_interfaces.html">
     ① Memory Interop and C++ abstract interfaces
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="cpp_elements.html">
     ② C++ elements
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="gstreamer_elements.html">
     ③ GStreamer Elements
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="gstreamer_bins.html">
     ③ GStreamer Bin Elements
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="python_bindings.html">
     ③ Python Bindings
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     PyTorch tensor inference [Preview]
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="elements_list.html">
     Elements 2.0
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="packaging.html">
     Packaging
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="samples_2.0.html">
     Samples 2.0
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="api_ref/index.html">
     API 2.0 Reference
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/>
    <label for="toctree-checkbox-15">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="api_ref/global.html">
       Global Namespace
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/>
      <label for="toctree-checkbox-16">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="api_ref/namespace_dlstreamer.html">
         namespace dlstreamer
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="api_ref/enum_GVALayout.html">
         enum GVALayout
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="api_ref/enum_GVAPrecision.html">
         enum GVAPrecision
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="api_ref/struct_GstGVAAudioEventMeta.html">
         struct GstGVAAudioEventMeta
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="api_ref/struct__GstGVAJSONMeta.html">
         struct _GstGVAJSONMeta
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="api_ref/struct__GstGVATensorMeta.html">
         struct _GstGVATensorMeta
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Theme by the <a href="https://ebp.jupyterbook.org">Executable Book Project</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../_sources/architecture_2.0/pytorch_inference.rst.txt"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.rst</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#prior-to-the-first-run">
   Prior to the first run
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#loading-model-and-weights">
   Loading model and weights
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#determining-tensor-shape">
   Determining tensor shape
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#dlstreamer-pipelines-with-pytorch-tensor-inference">
   DLStreamer pipelines with pytorch_tensor_inference
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#integration-into-bin-elements">
   Integration into bin-elements
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>PyTorch tensor inference [Preview]</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#prior-to-the-first-run">
   Prior to the first run
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#loading-model-and-weights">
   Loading model and weights
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#determining-tensor-shape">
   Determining tensor shape
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#dlstreamer-pipelines-with-pytorch-tensor-inference">
   DLStreamer pipelines with pytorch_tensor_inference
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#integration-into-bin-elements">
   Integration into bin-elements
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section id="pytorch-tensor-inference-preview">
<h1>PyTorch tensor inference [Preview]<a class="headerlink" href="#pytorch-tensor-inference-preview" title="Permalink to this headline">#</a></h1>
<p>DLStreamer supports Pytorch inference backend via the <code class="docutils literal notranslate"><span class="pre">pytorch_tensor_inference</span></code> GStreamer element implemented in Python. Element description can be found in <a class="reference internal" href="elements_list.html"><span class="doc">Elements 2.0 reference</span></a>.</p>
<section id="prior-to-the-first-run">
<h2>Prior to the first run<a class="headerlink" href="#prior-to-the-first-run" title="Permalink to this headline">#</a></h2>
<p>Before using <code class="docutils literal notranslate"><span class="pre">pytorch_tensor_inference</span></code>, make sure that all of the following requirements are met. Visit <span class="xref std std-doc">Install Guide</span> for more information about installing DLStreamer.</p>
<ol class="arabic simple">
<li><p><code class="docutils literal notranslate"><span class="pre">intel-dlstreamer-gst-python3-plugin-loader</span></code> and <code class="docutils literal notranslate"><span class="pre">intel-dlstreamer-gst-python3</span></code> packages are installed. If not, add DLStreamer apt repository and install the following packages:</p></li>
</ol>
<blockquote>
<div><div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>apt-get<span class="w"> </span>update
apt-get<span class="w"> </span>install<span class="w"> </span>-y<span class="w"> </span>python3-intel-dlstreamer
</pre></div>
</div>
</div></blockquote>
<ol class="arabic simple" start="2">
<li><p>Python requirements are installed. If not, install using <code class="docutils literal notranslate"><span class="pre">reqirements.txt</span></code> file:</p></li>
</ol>
<blockquote>
<div><div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>python3<span class="w"> </span>-m<span class="w"> </span>pip<span class="w"> </span>install<span class="w"> </span>--upgrade<span class="w"> </span>pip
python3<span class="w"> </span>-m<span class="w"> </span>pip<span class="w"> </span>install<span class="w"> </span>-r<span class="w"> </span>requirements.txt
</pre></div>
</div>
</div></blockquote>
<ol class="arabic simple" start="3">
<li><p>DLStreamer environment has been configured. If not:</p></li>
</ol>
<blockquote>
<div><div class="highlight-sh notranslate"><div class="highlight"><pre><span></span><span class="nb">source</span><span class="w"> </span>/opt/intel/dlstreamer/setupvars.sh
</pre></div>
</div>
</div></blockquote>
<ol class="arabic simple" start="4">
<li><p>Verify the GStreamer python loader plugin via:</p></li>
</ol>
<blockquote>
<div><div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>gst-inspect-1.0<span class="w"> </span>python
</pre></div>
</div>
<p>There should be no errors in the output and the list of GStreamer elements should contain <code class="docutils literal notranslate"><span class="pre">pytorch_tensor_inference</span></code>.</p>
</div></blockquote>
</section>
<section id="loading-model-and-weights">
<h2>Loading model and weights<a class="headerlink" href="#loading-model-and-weights" title="Permalink to this headline">#</a></h2>
<p><code class="docutils literal notranslate"><span class="pre">pytorch_tensor_inference</span></code> supports several options for loading model and weights.</p>
<ul class="simple">
<li><p>The easiest way to load model is to find the corresponding module in ‘torchvision’ library and specify its name in the <code class="docutils literal notranslate"><span class="pre">model</span></code> property. You need to specify the full import path of the model, for example: <code class="docutils literal notranslate"><span class="pre">pytorch_tensor_inference</span> <span class="pre">model=torchvision.models.resnet50</span></code>. In this case, if weights are not specified, <code class="docutils literal notranslate"><span class="pre">pytorch_tensor_inference</span></code> takes the default weights from torchvision. In our example, these will be the <code class="docutils literal notranslate"><span class="pre">ResNet50_Weights.DEFAULT</span></code> weights.</p></li>
<li><p>To use your custom weights for a model from <code class="docutils literal notranslate"><span class="pre">torchvision</span></code>, you need to specify the path to it using <code class="docutils literal notranslate"><span class="pre">model-weights</span></code> property: <code class="docutils literal notranslate"><span class="pre">pytorch_tensor_inference</span> <span class="pre">model=torchvision.models.resnet50</span> <span class="pre">model-weights=/path/to/model-weights.pt</span></code></p></li>
<li><p>It is also possible to specify the path to the saved file with the model. In this case, this path must be specified using the same property <code class="docutils literal notranslate"><span class="pre">model</span></code>: <code class="docutils literal notranslate"><span class="pre">pytorch_tensor_inference</span> <span class="pre">model=/path/to/model.pt</span></code></p></li>
</ul>
</section>
<section id="determining-tensor-shape">
<h2>Determining tensor shape<a class="headerlink" href="#determining-tensor-shape" title="Permalink to this headline">#</a></h2>
<p>PyTorch doesn’t provide static tensor shapes for input and output of a model. To obtain the size of the output tensors during caps negotiations phase, inference is performed on an random tensor, the size of which will be set in accordance with the capabilities.</p>
</section>
<section id="dlstreamer-pipelines-with-pytorch-tensor-inference">
<h2>DLStreamer pipelines with pytorch_tensor_inference<a class="headerlink" href="#dlstreamer-pipelines-with-pytorch-tensor-inference" title="Permalink to this headline">#</a></h2>
<p>Below is an example using the <code class="docutils literal notranslate"><span class="pre">pytorch_tensor_inference</span></code> element in pipeline to classify objects. This example uses the <code class="docutils literal notranslate"><span class="pre">resnet50</span></code> model from torchvision with default weights and <code class="docutils literal notranslate"><span class="pre">processbin</span></code> element to split stream data and merge it with inference results. Visit <a class="reference internal" href="elements_list.html"><span class="doc">Elements 2.0 reference</span></a> for more information on the <code class="docutils literal notranslate"><span class="pre">processbin</span></code> element.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>filesrc<span class="w"> </span><span class="nv">location</span><span class="o">=</span>input_file.mp4<span class="w"> </span>!<span class="w"> </span>decodebin<span class="w"> </span>!<span class="w"> </span><span class="se">\</span>
processbin<span class="w"> </span><span class="se">\</span>
<span class="w">  </span><span class="nv">preprocess</span><span class="o">=</span>videoscale<span class="w"> </span>!<span class="w"> </span>videoconvert<span class="w"> </span>!<span class="w"> </span>video/x-raw,format<span class="o">=</span>RGBP<span class="w"> </span>!<span class="w"> </span>tensor_convert<span class="w"> </span>!<span class="w"> </span>opencv_tensor_normalize<span class="w"> </span><span class="nv">range</span><span class="o">=</span>&lt;<span class="m">0</span>,1&gt;,<span class="w"> </span><span class="nv">mean</span><span class="o">=</span>&lt;<span class="m">0</span>.485,<span class="w"> </span><span class="m">0</span>.456,<span class="w"> </span><span class="m">0</span>.406&gt;,<span class="w"> </span><span class="nv">std</span><span class="o">=</span>&lt;<span class="m">0</span>.229,<span class="w"> </span><span class="m">0</span>.224,<span class="w"> </span><span class="m">0</span>.225&gt;<span class="w"> </span><span class="se">\</span>
<span class="w">  </span><span class="nv">process</span><span class="o">=</span>pytorch_tensor_inference<span class="w"> </span><span class="nv">model</span><span class="o">=</span>torchvision.models.resnet50<span class="w"> </span><span class="se">\</span>
<span class="w">  </span><span class="nv">postprocess</span><span class="o">=</span>tensor_postproc_label<span class="w"> </span><span class="nv">method</span><span class="o">=</span>softmax<span class="w"> </span>labels-file<span class="o">=</span>/dlstreamer_dir/samples/labels/imagenet_2012.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span><span class="nv">aggregate</span><span class="o">=</span>meta_aggregate<span class="w"> </span>!<span class="w"> </span><span class="se">\</span>
meta_overlay<span class="w"> </span>!<span class="w"> </span><span class="se">\</span>
autovideosink
</pre></div>
</div>
</section>
<section id="integration-into-bin-elements">
<h2>Integration into bin-elements<a class="headerlink" href="#integration-into-bin-elements" title="Permalink to this headline">#</a></h2>
<p>PyTorch tensor inference is included in inference bin elements such as <code class="docutils literal notranslate"><span class="pre">video_inference</span></code>, <code class="docutils literal notranslate"><span class="pre">object_detect</span></code> and <code class="docutils literal notranslate"><span class="pre">object_classify</span></code>. These elements construct sub-pipelines within themselves depending on the type of the specified model. So if it’s a file with Pytorch model or a module from torchvision, the bin element will automatically use PyTorch inference backend internally.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>filesrc<span class="w"> </span><span class="nv">location</span><span class="o">=</span>input_file.mp4<span class="w"> </span>!<span class="w"> </span>decodebin<span class="w"> </span>!<span class="w"> </span><span class="se">\</span>
object_detect<span class="w"> </span><span class="nv">model</span><span class="o">=</span>torchvision.models.detection.ssdlite320_mobilenet_v3_large<span class="w"> </span>labels-file<span class="o">=</span>coco_91cl_bkgr.txt<span class="w"> </span>!<span class="w"> </span><span class="se">\</span>
meta_overlay<span class="w"> </span>!<span class="w"> </span><span class="se">\</span>
autovideosink
</pre></div>
</div>
<p>Below is a graph showing how the <code class="docutils literal notranslate"><span class="pre">object_detect</span></code> bin will be built.</p>
<figure class="align-default" id="id1">
<div class="graphviz"><img src="../_images/graphviz-c3f4c3edeacd424971093ca6163d0dcfd3ebff28.png" alt="digraph {
  rankdir=&quot;LR&quot;
  node[shape=box, style=&quot;rounded, filled&quot;, fillcolor=white]

  tee[label=&quot;tee&quot;, fillcolor=gray95]
  preproc[label=&quot;preprocess=videoscale ! videoconvert ! video/x-raw,format=RGBP ! tensor_convert ! opencv_tensor_normalize range=&lt;0,1&gt;&quot;]
  processing[label=&quot;process=pytorch_tensor_inference model=torchvision.models.detection.ssdlite320_mobilenet_v3_large&quot;]
  postproc[label=&quot;postprocess=tensor_postproc_detection labels-file=coco_91cl_bkgr.txt&quot;]
  aggregate[label=&quot;aggregate=meta_aggregate&quot;]

  tee -&gt; preproc -&gt; processing -&gt; postproc -&gt; aggregate
  tee -&gt; aggregate
}" class="graphviz" /></div>
<figcaption>
<p><span class="caption-text">object_detect internal pipeline</span><a class="headerlink" href="#id1" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>By default, preprocessing will include color conversion to <code class="docutils literal notranslate"><span class="pre">RGB</span></code>, resizing to <code class="docutils literal notranslate"><span class="pre">resize_size</span></code> if it can be obtained from the model’s preprocessing information, and rescaling to <code class="docutils literal notranslate"><span class="pre">[0.0,</span> <span class="pre">1.0]</span></code>. If the model requires additional operations during preprocessing, it can be described using the model-proc file, which can then be specified in the bin element. As described in the model-proc file, the bin element will build the pre-processing pipeline. Visit <span class="xref std std-doc">How to Create Model-proc File</span> for more information on creating a model-proc file.</p>
</section>
</section>


              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="python_bindings.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">③ Python Bindings</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="elements_list.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Elements 2.0</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Intel Corporation<br/>
  
      &copy; Copyright 2022, Intel Corporation.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>