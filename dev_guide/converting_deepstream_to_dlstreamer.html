

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

    <title>Converting NVIDIA DeepStream Pipelines to Intel® Deep Learning Streamer (Intel® DL Streamer) Pipeline Framework &#8212; Intel® Deep Learning Streamer (Intel® DL Streamer)  documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=5b4479735964841361fd" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=5b4479735964841361fd" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../_static/doxyrest-pygments.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=5b4479735964841361fd" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd" />
  <script src="../_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=5b4479735964841361fd"></script>

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/sphinx_highlight.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script src="../_static/target-highlight.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'dev_guide/converting_deepstream_to_dlstreamer';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="How to Contribute" href="how_to_contribute.html" />
    <link rel="prev" title="Profiling with Intel VTune™" href="profiling.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
  
    <p class="title logo__title">Intel® Deep Learning Streamer (Intel® DL Streamer)  documentation</p>
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../get_started/get_started_index.html">Get Started</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../get_started/hardware_requirements.html">Hardware Requirements</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../get_started/install/install_guide_index.html">Install Guide</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../get_started/install/install_guide_ubuntu.html">Install Guide Ubuntu</a></li>
<li class="toctree-l3"><a class="reference internal" href="../get_started/install/uninstall_guide_ubuntu.html">Uninstall Guide Ubuntu</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../get_started/tutorial.html">Tutorial</a></li>
<li class="toctree-l2"><a class="reference internal" href="../get_started/flex_series/quick_start_guide.html">Quick Start Guide for Media Analytics on Intel® Data Center GPU Flex Series</a></li>



<li class="toctree-l2"><a class="reference external" href="https://github.com/dlstreamer/dlstreamer/blob/master/samples/gstreamer/README.md">Samples</a></li>
</ul>
</li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="dev_guide_index.html">Developer Guide</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="metadata.html">Metadata</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="model_preparation.html">Model Preparation</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="yolov5_model_preparation.html">Yolov5 Model Preparation Example</a></li>

</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="model_proc_file.html">Model-proc File</a></li>
<li class="toctree-l2"><a class="reference internal" href="how_to_create_model_proc_file.html">How to Create Model-proc File</a></li>
<li class="toctree-l2"><a class="reference internal" href="python_bindings.html">Python Bindings</a></li>
<li class="toctree-l2"><a class="reference internal" href="custom_processing.html">Custom Processing</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="object_tracking.html">Object Tracking</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="deepsort_implementation.html">DeepSORT tracking support</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="gpu_device_selection.html">GPU device selection</a></li>
<li class="toctree-l2"><a class="reference internal" href="profiling.html">Profiling with Intel VTune™</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Converting NVIDIA DeepStream Pipelines to Intel® Deep Learning Streamer (Intel® DL Streamer) Pipeline Framework</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="how_to_contribute.html">How to Contribute</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="coding_style.html">Coding Style</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="latency_tracer.html">Latency Tracer</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../elements/elements.html">Elements</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../elements/gvadetect.html">gvadetect</a></li>
<li class="toctree-l2"><a class="reference internal" href="../elements/gvaclassify.html">gvaclassify</a></li>
<li class="toctree-l2"><a class="reference internal" href="../elements/gvainference.html">gvainference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../elements/gvaaudiodetect.html">gvaaudiodetect</a></li>
<li class="toctree-l2"><a class="reference internal" href="../elements/gvatrack.html">gvatrack</a></li>
<li class="toctree-l2"><a class="reference internal" href="../elements/gvametaconvert.html">gvametaconvert</a></li>
<li class="toctree-l2"><a class="reference internal" href="../elements/gvametapublish.html">gvametapublish</a></li>
<li class="toctree-l2"><a class="reference internal" href="../elements/gvametaaggregate.html">gvametaaggregate</a></li>
<li class="toctree-l2"><a class="reference internal" href="../elements/gvapython.html">gvapython</a></li>
<li class="toctree-l2"><a class="reference internal" href="../elements/gvawatermark.html">gvawatermark</a></li>
<li class="toctree-l2"><a class="reference internal" href="../elements/gvafpscounter.html">gvafpscounter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../elements/python_object_association.html">python_object_association</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../supported_models.html">Supported Models</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../api_ref/api_reference.html">API Reference</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../api_ref/page_index.html">Intel® Deep Learning Streamer (Intel® DL Streamer) API reference</a></li>




<li class="toctree-l2 has-children"><a class="reference internal" href="../api_ref/global.html">Global Namespace</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-9"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api_ref/namespace_gstgva.html">namespace gstgva</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-10"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_ref/namespace_gstgva_region_of_interest.html">namespace gstgva::region_of_interest</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_ref/namespace_gstgva_tensor.html">namespace gstgva::tensor</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_ref/namespace_gstgva_video_frame.html">namespace gstgva::video_frame</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api_ref/enum_GVALayout.html">enum GVALayout</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api_ref/enum_GVAPrecision.html">enum GVAPrecision</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api_ref/struct_GstGVAAudioEventMeta.html">struct GstGVAAudioEventMeta</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-11"><i class="fa-solid fa-chevron-down"></i></label><ul class="simple">
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api_ref/struct__GstGVAJSONMeta.html">struct _GstGVAJSONMeta</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-12"><i class="fa-solid fa-chevron-down"></i></label><ul class="simple">
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api_ref/struct__GstGVATensorMeta.html">struct _GstGVATensorMeta</a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-13"><i class="fa-solid fa-chevron-down"></i></label><ul class="simple">
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../architecture_2.0/architecture_2.0.html">Architecture 2.0 [Preview]</a><input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-14"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../architecture_2.0/migration_guide.html">Migration to 2.0</a></li>
<li class="toctree-l2"><a class="reference internal" href="../architecture_2.0/cpp_interfaces.html">① Memory Interop and C++ abstract interfaces</a></li>
<li class="toctree-l2"><a class="reference internal" href="../architecture_2.0/cpp_elements.html">② C++ elements</a></li>
<li class="toctree-l2"><a class="reference internal" href="../architecture_2.0/gstreamer_elements.html">③ GStreamer Elements</a></li>
<li class="toctree-l2"><a class="reference internal" href="../architecture_2.0/gstreamer_bins.html">③ GStreamer Bin Elements</a></li>
<li class="toctree-l2"><a class="reference internal" href="../architecture_2.0/python_bindings.html">③ Python Bindings</a></li>
<li class="toctree-l2"><a class="reference internal" href="../architecture_2.0/pytorch_inference.html">PyTorch tensor inference [Preview]</a></li>
<li class="toctree-l2"><a class="reference internal" href="../architecture_2.0/elements_list.html">Elements 2.0</a></li>
<li class="toctree-l2"><a class="reference internal" href="../architecture_2.0/packaging.html">Packaging</a></li>
<li class="toctree-l2"><a class="reference internal" href="../architecture_2.0/samples_2.0.html">Samples 2.0</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../architecture_2.0/api_ref/index.html">API 2.0 Reference</a><input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-15"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../architecture_2.0/api_ref/global.html">Global Namespace</a><input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-16"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../architecture_2.0/api_ref/namespace_GVA.html">namespace GVA</a></li>
<li class="toctree-l4"><a class="reference internal" href="../architecture_2.0/api_ref/namespace_dlstreamer.html">namespace dlstreamer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../architecture_2.0/api_ref/enum_GVALayout.html">enum GVALayout</a></li>
<li class="toctree-l4"><a class="reference internal" href="../architecture_2.0/api_ref/enum_GVAPrecision.html">enum GVAPrecision</a></li>
<li class="toctree-l4"><a class="reference internal" href="../architecture_2.0/api_ref/struct_GstGVAAudioEventMeta.html">struct GstGVAAudioEventMeta</a></li>
<li class="toctree-l4"><a class="reference internal" href="../architecture_2.0/api_ref/struct__GstGVAJSONMeta.html">struct _GstGVAJSONMeta</a></li>
<li class="toctree-l4"><a class="reference internal" href="../architecture_2.0/api_ref/struct__GstGVATensorMeta.html">struct _GstGVATensorMeta</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/dev_guide/converting_deepstream_to_dlstreamer.rst" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.rst</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Converting NVIDIA DeepStream Pipelines to Intel® Deep Learning Streamer (Intel® DL Streamer) Pipeline Framework</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#preparing-your-model">Preparing Your Model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gstreamer-pipeline-adjustments">GStreamer Pipeline Adjustments</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mux-and-demux-elements">Mux and Demux Elements</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#inferencing-elements">Inferencing Elements</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#video-processing-elements">Video Processing Elements</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#metadata-elements">Metadata Elements</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#multiple-input-streams">Multiple Input Streams</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section id="converting-nvidia-deepstream-pipelines-to-intel-deep-learning-streamer-intel-dl-streamer-pipeline-framework">
<h1>Converting NVIDIA DeepStream Pipelines to Intel® Deep Learning Streamer (Intel® DL Streamer) Pipeline Framework<a class="headerlink" href="#converting-nvidia-deepstream-pipelines-to-intel-deep-learning-streamer-intel-dl-streamer-pipeline-framework" title="Permalink to this heading">#</a></h1>
<p>This document will describe the steps to convert a pipeline from NVIDIA
DeepStream to Intel® DL Streamer Pipeline Framework.
We also have a running example through the document that will be updated at
each step to help show the modifications being described.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The intermediate steps of the pipeline are not meant to run. They are simply
there as a reference example of the changes being made in each section.</p>
</div>
<section id="preparing-your-model">
<h2>Preparing Your Model<a class="headerlink" href="#preparing-your-model" title="Permalink to this heading">#</a></h2>
<p>To use Intel® DL Streamer Pipeline Framework and OpenVINO™ Toolkit the
model needs to be in Intermediate Representation (IR) format. To convert
your model to this format, use the <a class="reference external" href="https://docs.openvino.ai/latest/openvino_docs_MO_DG_Deep_Learning_Model_Optimizer_DevGuide.html">Model Optimizer</a>
tool from OpenVINO™ Toolkit.</p>
<p>Pipeline Framework’s inference plugins optionally can do some pre- and
post-processing operations before/after running inference. These
operations are specified in a model-proc file. Visit <a class="reference internal" href="model_preparation.html"><span class="doc">this page</span></a>
for more information on creating a model-proc file and examples with
various models from <a class="reference external" href="https://github.com/openvinotoolkit/open_model_zoo">Open Model Zoo</a>.</p>
</section>
<section id="gstreamer-pipeline-adjustments">
<h2>GStreamer Pipeline Adjustments<a class="headerlink" href="#gstreamer-pipeline-adjustments" title="Permalink to this heading">#</a></h2>
<p>In the following sections we will be converting the below pipeline that
is using DeepStream elements to Pipeline Framework. It is taken from one of the
examples
<a class="reference external" href="https://github.com/NVIDIA-AI-IOT/redaction_with_deepstream">here</a>.
It takes an input stream from file, decodes, runs inference, overlays
the inferences on the video, re-encodes and outputs a new .mp4 file.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>filesrc<span class="w"> </span><span class="nv">location</span><span class="o">=</span>input_file.mp4<span class="w"> </span>!<span class="w"> </span>decodebin<span class="w"> </span>!<span class="w"> </span><span class="se">\</span>
nvstreammux<span class="w"> </span>batch-size<span class="o">=</span><span class="m">1</span><span class="w"> </span><span class="nv">width</span><span class="o">=</span><span class="m">1920</span><span class="w"> </span><span class="nv">height</span><span class="o">=</span><span class="m">1080</span><span class="w"> </span>!<span class="w"> </span>queue<span class="w"> </span>!<span class="w"> </span><span class="se">\</span>
nvinfer<span class="w"> </span>config-file-path<span class="o">=</span>./config.txt<span class="w"> </span>!<span class="w"> </span><span class="se">\</span>
nvvideoconvert<span class="w"> </span>!<span class="w"> </span><span class="s2">&quot;video/x-raw(memory:NVMM), format=RGBA&quot;</span><span class="w"> </span>!<span class="w"> </span><span class="se">\</span>
nvdsosd<span class="w"> </span>!<span class="w"> </span>queue<span class="w"> </span>!<span class="w"> </span><span class="se">\</span>
nvvideoconvert<span class="w"> </span>!<span class="w"> </span><span class="s2">&quot;video/x-raw, format=I420&quot;</span><span class="w"> </span>!<span class="w"> </span>videoconvert<span class="w"> </span>!<span class="w"> </span>avenc_mpeg4<span class="w"> </span><span class="nv">bitrate</span><span class="o">=</span><span class="m">8000000</span><span class="w"> </span>!<span class="w"> </span>qtmux<span class="w"> </span>!<span class="w"> </span>filesink<span class="w"> </span><span class="nv">location</span><span class="o">=</span>output_file.mp4
</pre></div>
</div>
<section id="mux-and-demux-elements">
<h3>Mux and Demux Elements<a class="headerlink" href="#mux-and-demux-elements" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>Remove <code class="docutils literal notranslate"><span class="pre">nvstreammux</span></code> and <code class="docutils literal notranslate"><span class="pre">nvstreamdemux</span></code> and all their
properties.</p>
<ul>
<li><p>These elements are used in the case of multiple input streams to
connect all inputs to the same inferencing element. In DL
Streamer, the inferencing elements share properties and instances
if they share the same <code class="docutils literal notranslate"><span class="pre">model-instance-id</span></code> property.</p></li>
<li><p>In our example, we only have one source so we will skip this for
now. See more on how to do this with Pipeline Framework in the section
<a class="reference internal" href="#multiple-input-streams"><span class="std std-ref">Multiple Input Streams</span></a> below.</p></li>
</ul>
</li>
</ul>
<p>At this stage we have removed <code class="docutils literal notranslate"><span class="pre">nvstreammux</span></code> and the <code class="docutils literal notranslate"><span class="pre">queue</span></code> that
followed it. Notably, the <code class="docutils literal notranslate"><span class="pre">batch-size</span></code> property is also removed. It
will be added in the next section as a property of the Pipeline Framework
inference elements.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>filesrc<span class="w"> </span><span class="nv">location</span><span class="o">=</span>input_file.mp4<span class="w"> </span>!<span class="w"> </span>decodebin<span class="w"> </span>!<span class="w"> </span><span class="se">\</span>
nvinfer<span class="w"> </span>config-file-path<span class="o">=</span>./config.txt<span class="w"> </span>!<span class="w"> </span><span class="se">\</span>
nvvideoconvert<span class="w"> </span>!<span class="w"> </span><span class="s2">&quot;video/x-raw(memory:NVMM), format=RGBA&quot;</span><span class="w"> </span>!<span class="w"> </span><span class="se">\</span>
nvdsosd<span class="w"> </span>!<span class="w"> </span>queue<span class="w"> </span>!<span class="w"> </span><span class="se">\</span>
nvvideoconvert<span class="w"> </span>!<span class="w"> </span><span class="s2">&quot;video/x-raw, format=I420&quot;</span><span class="w"> </span>!<span class="w"> </span>videoconvert<span class="w"> </span>!<span class="w"> </span>avenc_mpeg4<span class="w"> </span><span class="nv">bitrate</span><span class="o">=</span><span class="m">8000000</span><span class="w"> </span>!<span class="w"> </span>qtmux<span class="w"> </span>!<span class="w"> </span>filesink<span class="w"> </span><span class="nv">location</span><span class="o">=</span>output_file.mp4
</pre></div>
</div>
</section>
<section id="inferencing-elements">
<h3>Inferencing Elements<a class="headerlink" href="#inferencing-elements" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>Remove <code class="docutils literal notranslate"><span class="pre">nvinfer</span></code> and replace it with <code class="docutils literal notranslate"><span class="pre">gvainference</span></code>,
<code class="docutils literal notranslate"><span class="pre">gvadetect</span></code> or <code class="docutils literal notranslate"><span class="pre">gvaclassify</span></code> depending on the following use
cases:</p>
<ul>
<li><p>For doing detection on full frames and outputting a region of
interest, use
<a class="reference internal" href="../elements/gvadetect.html"><span class="doc">gvadetect</span></a>.
This replaces <code class="docutils literal notranslate"><span class="pre">nvinfer</span></code> when it is used in primary mode.</p>
<ul>
<li><p>Replace <code class="docutils literal notranslate"><span class="pre">config-file-path</span></code> property with <code class="docutils literal notranslate"><span class="pre">model</span></code> and
<code class="docutils literal notranslate"><span class="pre">model-proc</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">gvadetect</span></code> generates GstVideoRegionOfInterestMeta.</p></li>
</ul>
</li>
<li><p>For doing classification on previously detected objects, use
<a class="reference internal" href="../elements/gvaclassify.html"><span class="doc">gvaclassify</span></a>.
This replaces nvinfer when it is used in secondary mode.</p>
<ul>
<li><p>Replace <code class="docutils literal notranslate"><span class="pre">config-file-path</span></code> property with <code class="docutils literal notranslate"><span class="pre">model</span></code> and
<code class="docutils literal notranslate"><span class="pre">model-proc</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">gvaclassify</span></code> requires GstVideoRegionOfInterestMeta as input.</p></li>
</ul>
</li>
<li><p>For doing generic full frame inference, use
<a class="reference internal" href="../elements/gvainference.html"><span class="doc">gvainference</span></a>.
This replaces <code class="docutils literal notranslate"><span class="pre">nvinfer</span></code> when used in primary mode.</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">gvainference</span></code> generates GstGVATensorMeta.</p></li>
</ul>
</li>
</ul>
</li>
</ul>
<p>In this example we will use gvadetect to infer on the full frame and
output region of interests. <code class="docutils literal notranslate"><span class="pre">batch-size</span></code> was also added for
consistency with what was removed above (the default value is 1 so it is
not needed). We replaced <code class="docutils literal notranslate"><span class="pre">config-file-path</span></code> property with <code class="docutils literal notranslate"><span class="pre">model</span></code>
and <code class="docutils literal notranslate"><span class="pre">model-proc</span></code> properties. See the section above about “Preparing
your model” for converting the model to IR format and creating a
model-proc file.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The <code class="docutils literal notranslate"><span class="pre">model-proc</span></code> file is not always needed depending on the model’s inputs and outputs.</p>
</div>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>filesrc<span class="w"> </span><span class="nv">location</span><span class="o">=</span>input_file.mp4<span class="w"> </span>!<span class="w"> </span>decodebin<span class="w"> </span>!<span class="w"> </span><span class="se">\</span>
gvadetect<span class="w"> </span><span class="nv">model</span><span class="o">=</span>./model.xml<span class="w"> </span>model-proc<span class="o">=</span>./model_proc.json<span class="w"> </span>batch-size<span class="o">=</span><span class="m">1</span><span class="w"> </span>!<span class="w"> </span><span class="se">\</span>
nvvideoconvert<span class="w"> </span>!<span class="w"> </span><span class="s2">&quot;video/x-raw(memory:NVMM), format=RGBA&quot;</span><span class="w"> </span>!<span class="w"> </span><span class="se">\</span>
nvdsosd<span class="w"> </span>!<span class="w"> </span>queue<span class="w"> </span>!<span class="w"> </span><span class="se">\</span>
nvvideoconvert<span class="w"> </span>!<span class="w"> </span><span class="s2">&quot;video/x-raw, format=I420&quot;</span><span class="w"> </span>!<span class="w"> </span>videoconvert<span class="w"> </span>!<span class="w"> </span>avenc_mpeg4<span class="w"> </span><span class="nv">bitrate</span><span class="o">=</span><span class="m">8000000</span><span class="w"> </span>!<span class="w"> </span>qtmux<span class="w"> </span>!<span class="w"> </span>filesink<span class="w"> </span><span class="nv">location</span><span class="o">=</span>output_file.mp4
</pre></div>
</div>
</section>
<section id="video-processing-elements">
<h3>Video Processing Elements<a class="headerlink" href="#video-processing-elements" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>Replace video processing elements with vaapi equivalents for GPU or
native GStreamer elements for CPU.</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">nvvideoconvert</span></code> with <code class="docutils literal notranslate"><span class="pre">vaapipostproc</span></code> or <code class="docutils literal notranslate"><span class="pre">mfxvpp</span></code> (GPU) or
<code class="docutils literal notranslate"><span class="pre">videoconvert</span></code> (CPU).</p>
<ul>
<li><p>If the <code class="docutils literal notranslate"><span class="pre">nvvideoconvert</span></code> is being used to convert to/from
<code class="docutils literal notranslate"><span class="pre">memory:NVMM</span></code> it can just be removed.</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">nvv4ldecoder</span></code> can be replaced with <code class="docutils literal notranslate"><span class="pre">vaapi{CODEC}dec</span></code>, for
example <code class="docutils literal notranslate"><span class="pre">vaapih264dec</span></code> for decode only or <code class="docutils literal notranslate"><span class="pre">vaapidecodebin</span></code> for
decode and vaapipostproc. Alternatively, the native GStreamer
element <code class="docutils literal notranslate"><span class="pre">decodebin</span></code> can be used to automatically choose an
available decoder.</p></li>
</ul>
</li>
<li><p>Some caps filters that follow an inferencing element may need to be
adjusted or removed. Pipeline Framework inferencing elements do not support
color space conversion in post-processing. You will need to have a
<code class="docutils literal notranslate"><span class="pre">vaapipostproc</span></code> or <code class="docutils literal notranslate"><span class="pre">videoconvert</span></code> element to handle this.</p></li>
</ul>
<p>Here we removed a few caps filters and instances of <code class="docutils literal notranslate"><span class="pre">nvvideoconvert</span></code>
used for conversions from DeepStream’s NVMM because Pipeline Framework uses
standard GStreamer structures and memory types. We will leave the
standard gstreamer element <code class="docutils literal notranslate"><span class="pre">videoconvert</span></code> to do color space conversion
on CPU, however if available, we suggest using <code class="docutils literal notranslate"><span class="pre">vaapipostproc</span></code> to run
on Intel Graphics. Also, we will use the GStreamer standard element
<code class="docutils literal notranslate"><span class="pre">decodebin</span></code> to choose an appropriate demuxer and decoder depending on
the input stream as well as what is available on the system.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>filesrc<span class="w"> </span><span class="nv">location</span><span class="o">=</span>input_file.mp4<span class="w"> </span>!<span class="w"> </span>decodebin<span class="w"> </span>!<span class="w"> </span><span class="se">\</span>
gvadetect<span class="w"> </span><span class="nv">model</span><span class="o">=</span>./model.xml<span class="w"> </span>model-proc<span class="o">=</span>./model_proc.json<span class="w"> </span>batch-size<span class="o">=</span><span class="m">1</span><span class="w"> </span>!<span class="w"> </span><span class="se">\</span>
nvdsosd<span class="w"> </span>!<span class="w"> </span>queue<span class="w"> </span>!<span class="w"> </span><span class="se">\</span>
videoconvert<span class="w"> </span>!<span class="w"> </span>avenc_mpeg4<span class="w"> </span><span class="nv">bitrate</span><span class="o">=</span><span class="m">8000000</span><span class="w"> </span>!<span class="w"> </span>qtmux<span class="w"> </span>!<span class="w"> </span>filesink<span class="w"> </span><span class="nv">location</span><span class="o">=</span>output_file.mp4
</pre></div>
</div>
</section>
<section id="metadata-elements">
<h3>Metadata Elements<a class="headerlink" href="#metadata-elements" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>Replace <code class="docutils literal notranslate"><span class="pre">nvtracker</span></code> with
<a class="reference internal" href="../elements/gvatrack.html"><span class="doc">gvatrack</span></a></p>
<ul>
<li><p>Remove <code class="docutils literal notranslate"><span class="pre">ll-lib-file</span></code> property. Optionally replace with
<code class="docutils literal notranslate"><span class="pre">tracking-type</span></code> if you want to specify the algorithm used. By
default it will use the ‘short-term’ tracker.</p></li>
<li><p>Remove all other properties.</p></li>
</ul>
</li>
<li><p>Replace <code class="docutils literal notranslate"><span class="pre">nvdsosd</span></code> with
<a class="reference internal" href="../elements/gvawatermark.html"><span class="doc">gvawatermark</span></a></p>
<ul>
<li><p>Remove all properties</p></li>
</ul>
</li>
<li><p>Replace <code class="docutils literal notranslate"><span class="pre">nvmsgconv</span></code> with
<a class="reference internal" href="../elements/gvametaconvert.html"><span class="doc">gvametaconvert</span></a></p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">gvametaconvert</span></code> can be used to convert metadata from
inferencing elements to JSON and to output metadata to the
GST_DEBUG log.</p></li>
<li><p>It has optional properties to configure what information goes into
the JSON object including frame data for frames with no detections
found, tensor data, the source the inferences came from, and tags,
a user defined JSON object that is attached to each output for
additional custom data.</p></li>
</ul>
</li>
<li><p>Replace <code class="docutils literal notranslate"><span class="pre">nvmsgbroker</span></code> with
<a class="reference internal" href="../elements/gvametapublish.html"><span class="doc">gvametapublish</span></a></p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">gvametapublish</span></code> can be used to output the JSON messages
generated by <code class="docutils literal notranslate"><span class="pre">gvametaconvert</span></code> to stdout, file, MQTT or Kafka.</p></li>
</ul>
</li>
</ul>
<p>The only metadata processing that is done in this pipeline is to overlay
the inferences on the video for which we use <code class="docutils literal notranslate"><span class="pre">gvawatermark</span></code>.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>filesrc<span class="w"> </span><span class="nv">location</span><span class="o">=</span>input_file.mp4<span class="w"> </span>!<span class="w"> </span>decodebin<span class="w"> </span>!<span class="w"> </span><span class="se">\</span>
gvadetect<span class="w"> </span><span class="nv">model</span><span class="o">=</span>./model.xml<span class="w"> </span>model-proc<span class="o">=</span>./model_proc.json<span class="w"> </span>batch-size<span class="o">=</span><span class="m">1</span><span class="w"> </span>!<span class="w"> </span><span class="se">\</span>
gvawatermark<span class="w"> </span>!<span class="w"> </span>queue<span class="w"> </span>!<span class="w"> </span><span class="se">\</span>
videoconvert<span class="w"> </span>!<span class="w"> </span>avenc_mpeg4<span class="w"> </span><span class="nv">bitrate</span><span class="o">=</span><span class="m">8000000</span><span class="w"> </span>!<span class="w"> </span>qtmux<span class="w"> </span>!<span class="w"> </span>filesink<span class="w"> </span><span class="nv">location</span><span class="o">=</span>output_file.mp4
</pre></div>
</div>
</section>
</section>
<section id="multiple-input-streams">
<span id="id1"></span><h2>Multiple Input Streams<a class="headerlink" href="#multiple-input-streams" title="Permalink to this heading">#</a></h2>
<div class="line-block">
<div class="line">Unlike DeepStream, where all sources need to be linked to the sink
pads of the <code class="docutils literal notranslate"><span class="pre">nvstreammux</span></code> element, Pipeline Framework shares all model and
Inference Engine properties between elements that have the same
<code class="docutils literal notranslate"><span class="pre">model-instance-id</span></code> property. Meaning that you do not need to mux
all sources together before inference and you can remove any
instances of <code class="docutils literal notranslate"><span class="pre">nvstreammux</span></code> and <code class="docutils literal notranslate"><span class="pre">nvstreamdemux</span></code>. Below is a pseudo
example of a pipeline with two streams.</div>
<div class="line">For DeepStream, the pipeline would look like this:</div>
</div>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>nvstreammux<span class="w"> </span>!<span class="w"> </span>nvinfer<span class="w"> </span>config-file-path<span class="o">=</span>./config.txt<span class="w"> </span>!<span class="w"> </span>nvstreamdemux<span class="w"> </span>filesrc<span class="w"> </span>!<span class="w"> </span>decode<span class="w"> </span>!<span class="w"> </span>mux.sink_0<span class="w"> </span>filesrc<span class="w"> </span>!<span class="w"> </span>decode<span class="w"> </span>!<span class="w"> </span>mux.sink_1<span class="w"> </span>demux.src_0<span class="w"> </span>!<span class="w"> </span>encode<span class="w"> </span>!<span class="w"> </span>filesink<span class="w"> </span>demux.src_1<span class="w"> </span>!<span class="w"> </span>encode<span class="w"> </span>!<span class="w"> </span>filesink
</pre></div>
</div>
<p>When using Pipeline Framework, the pipeline will look like this:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>filesrc<span class="w"> </span>!<span class="w"> </span>decode<span class="w"> </span>!<span class="w"> </span>gvadetect<span class="w"> </span><span class="nv">model</span><span class="o">=</span>./model.xml<span class="w"> </span>model-proc<span class="o">=</span>./model_proc.json<span class="w"> </span>model-instance-id<span class="o">=</span>model1<span class="w"> </span>!<span class="w"> </span>encode<span class="w"> </span>!<span class="w"> </span>filesink<span class="w"> </span>filesrc<span class="w"> </span>!<span class="w"> </span>decode<span class="w"> </span>!<span class="w"> </span>gvadetect<span class="w"> </span>model-instance-id<span class="o">=</span>model1<span class="w"> </span>!<span class="w"> </span>encode<span class="w"> </span>!<span class="w"> </span>filesink
</pre></div>
</div>
</section>
</section>


                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="profiling.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Profiling with Intel VTune™</p>
      </div>
    </a>
    <a class="right-next"
       href="how_to_contribute.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">How to Contribute</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#preparing-your-model">Preparing Your Model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gstreamer-pipeline-adjustments">GStreamer Pipeline Adjustments</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mux-and-demux-elements">Mux and Demux Elements</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#inferencing-elements">Inferencing Elements</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#video-processing-elements">Video Processing Elements</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#metadata-elements">Metadata Elements</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#multiple-input-streams">Multiple Input Streams</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Intel Corporation
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023, Intel Corporation.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=5b4479735964841361fd"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>