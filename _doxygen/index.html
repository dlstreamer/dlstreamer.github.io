

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

    <title>Intel® Deep Learning Streamer (Intel® DL Streamer) API reference &#8212; Intel® Deep Learning Streamer (Intel® DL Streamer)  documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=5b4479735964841361fd" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=5b4479735964841361fd" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../_static/doxyrest-pygments.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=5b4479735964841361fd" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd" />
  <script src="../_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=5b4479735964841361fd"></script>

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/sphinx_highlight.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script src="../_static/target-highlight.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '_doxygen/index';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
  
    <p class="title logo__title">Intel® Deep Learning Streamer (Intel® DL Streamer)  documentation</p>
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../get_started/get_started_index.html">Get Started</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../get_started/hardware_requirements.html">Hardware Requirements</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../get_started/install/install_guide_index.html">Install Guide</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../get_started/install/install_guide_ubuntu.html">Install Guide Ubuntu</a></li>
<li class="toctree-l3"><a class="reference internal" href="../get_started/install/uninstall_guide_ubuntu.html">Uninstall Guide Ubuntu</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../get_started/tutorial.html">Tutorial</a></li>
<li class="toctree-l2"><a class="reference internal" href="../get_started/flex_series/quick_start_guide.html">Quick Start Guide for Media Analytics on Intel® Data Center GPU Flex Series</a></li>



<li class="toctree-l2"><a class="reference external" href="https://github.com/dlstreamer/dlstreamer/blob/master/samples/gstreamer/README.md">Samples</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../dev_guide/dev_guide_index.html">Developer Guide</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../dev_guide/metadata.html">Metadata</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../dev_guide/model_preparation.html">Model Preparation</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../dev_guide/yolo_models.html">Yolo Models</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../dev_guide/model_proc_file.html">Model-proc File</a></li>
<li class="toctree-l2"><a class="reference internal" href="../dev_guide/model_info_xml.html">Model Info Section</a></li>
<li class="toctree-l2"><a class="reference internal" href="../dev_guide/how_to_create_model_proc_file.html">How to Create Model-proc File</a></li>
<li class="toctree-l2"><a class="reference internal" href="../dev_guide/python_bindings.html">Python Bindings</a></li>
<li class="toctree-l2"><a class="reference internal" href="../dev_guide/custom_processing.html">Custom Processing</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../dev_guide/object_tracking.html">Object Tracking</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../dev_guide/deepsort_implementation.html">DeepSORT tracking support</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../dev_guide/gpu_device_selection.html">GPU device selection</a></li>
<li class="toctree-l2"><a class="reference internal" href="../dev_guide/performance_guide.html">Performance Guide</a></li>
<li class="toctree-l2"><a class="reference internal" href="../dev_guide/profiling.html">Profiling with Intel VTune™</a></li>
<li class="toctree-l2"><a class="reference internal" href="../dev_guide/converting_deepstream_to_dlstreamer.html">Converting NVIDIA DeepStream Pipelines to Intel® Deep Learning Streamer (Intel® DL Streamer) Pipeline Framework</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../dev_guide/how_to_contribute.html">How to Contribute</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../dev_guide/coding_style.html">Coding Style</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../dev_guide/latency_tracer.html">Latency Tracer</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../elements/elements.html">Elements</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../elements/gvadetect.html">gvadetect</a></li>
<li class="toctree-l2"><a class="reference internal" href="../elements/gvaclassify.html">gvaclassify</a></li>
<li class="toctree-l2"><a class="reference internal" href="../elements/gvainference.html">gvainference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../elements/gvaaudiodetect.html">gvaaudiodetect</a></li>
<li class="toctree-l2"><a class="reference internal" href="../elements/gvatrack.html">gvatrack</a></li>
<li class="toctree-l2"><a class="reference internal" href="../elements/gvametaconvert.html">gvametaconvert</a></li>
<li class="toctree-l2"><a class="reference internal" href="../elements/gvametapublish.html">gvametapublish</a></li>
<li class="toctree-l2"><a class="reference internal" href="../elements/gvametaaggregate.html">gvametaaggregate</a></li>
<li class="toctree-l2"><a class="reference internal" href="../elements/gvapython.html">gvapython</a></li>
<li class="toctree-l2"><a class="reference internal" href="../elements/gvawatermark.html">gvawatermark</a></li>
<li class="toctree-l2"><a class="reference internal" href="../elements/gvafpscounter.html">gvafpscounter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../elements/gvaattachroi.html">gvaattachroi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../elements/python_object_association.html">python_object_association</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../supported_models.html">Supported Models</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../api_ref/api_reference.html">API Reference</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../api_ref/page_index.html">Intel® Deep Learning Streamer (Intel® DL Streamer) API reference</a></li>




<li class="toctree-l2 has-children"><a class="reference internal" href="../api_ref/global.html">Global Namespace</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-9"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api_ref/namespace_gstgva.html">namespace gstgva</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-10"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_ref/namespace_gstgva_region_of_interest.html">namespace gstgva::region_of_interest</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_ref/namespace_gstgva_tensor.html">namespace gstgva::tensor</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_ref/namespace_gstgva_video_frame.html">namespace gstgva::video_frame</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api_ref/enum_GVALayout.html">enum GVALayout</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api_ref/enum_GVAPrecision.html">enum GVAPrecision</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api_ref/struct_GstGVAAudioEventMeta.html">struct GstGVAAudioEventMeta</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-11"><i class="fa-solid fa-chevron-down"></i></label><ul class="simple">
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api_ref/struct__GstGVAJSONMeta.html">struct _GstGVAJSONMeta</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-12"><i class="fa-solid fa-chevron-down"></i></label><ul class="simple">
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api_ref/struct__GstGVATensorMeta.html">struct _GstGVATensorMeta</a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-13"><i class="fa-solid fa-chevron-down"></i></label><ul class="simple">
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../architecture_2.0/architecture_2.0.html">Architecture 2.0 [Preview]</a><input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-14"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../architecture_2.0/migration_guide.html">Migration to 2.0</a></li>
<li class="toctree-l2"><a class="reference internal" href="../architecture_2.0/cpp_interfaces.html">① Memory Interop and C++ abstract interfaces</a></li>
<li class="toctree-l2"><a class="reference internal" href="../architecture_2.0/cpp_elements.html">② C++ elements</a></li>
<li class="toctree-l2"><a class="reference internal" href="../architecture_2.0/gstreamer_elements.html">③ GStreamer Elements</a></li>
<li class="toctree-l2"><a class="reference internal" href="../architecture_2.0/gstreamer_bins.html">③ GStreamer Bin Elements</a></li>
<li class="toctree-l2"><a class="reference internal" href="../architecture_2.0/python_bindings.html">③ Python Bindings</a></li>
<li class="toctree-l2"><a class="reference internal" href="../architecture_2.0/pytorch_inference.html">PyTorch tensor inference [Preview]</a></li>
<li class="toctree-l2"><a class="reference internal" href="../architecture_2.0/elements_list.html">Elements 2.0</a></li>
<li class="toctree-l2"><a class="reference internal" href="../architecture_2.0/packaging.html">Packaging</a></li>
<li class="toctree-l2"><a class="reference internal" href="../architecture_2.0/samples_2.0.html">Samples 2.0</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../architecture_2.0/api_ref/index.html">API 2.0 Reference</a><input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-15"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../architecture_2.0/api_ref/global.html">Global Namespace</a><input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-16"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../architecture_2.0/api_ref/namespace_GVA.html">namespace GVA</a></li>
<li class="toctree-l4"><a class="reference internal" href="../architecture_2.0/api_ref/namespace_dlstreamer.html">namespace dlstreamer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../architecture_2.0/api_ref/enum_GVALayout.html">enum GVALayout</a></li>
<li class="toctree-l4"><a class="reference internal" href="../architecture_2.0/api_ref/enum_GVAPrecision.html">enum GVAPrecision</a></li>
<li class="toctree-l4"><a class="reference internal" href="../architecture_2.0/api_ref/struct_GstGVAAudioEventMeta.html">struct GstGVAAudioEventMeta</a></li>
<li class="toctree-l4"><a class="reference internal" href="../architecture_2.0/api_ref/struct__GstGVAJSONMeta.html">struct _GstGVAJSONMeta</a></li>
<li class="toctree-l4"><a class="reference internal" href="../architecture_2.0/api_ref/struct__GstGVATensorMeta.html">struct _GstGVATensorMeta</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/_doxygen/index.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Intel® Deep Learning Streamer (Intel® DL Streamer) API reference</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#overview">Overview</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#inference-results-flow">Inference results flow</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#print-inference-results-example">Print inference results example</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#access-inference-results-with-low-level-c-code">1. Access inference results with low-level C code</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#access-inference-results-with-c-api">2. Access inference results with C++ API</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#access-inference-results-with-python-api">3. Access inference results with Python API</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#custom-post-processing-tutorial">Custom post-processing tutorial</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section id="intel-deep-learning-streamer-intel-dl-streamer-api-reference">
<h1>Intel® Deep Learning Streamer (Intel® DL Streamer) API reference<a class="headerlink" href="#intel-deep-learning-streamer-intel-dl-streamer-api-reference" title="Permalink to this heading">#</a></h1>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this heading">#</a></h2>
<p>This documentation describes Intel® DL Streamer metadata API (Application Programming Interface) that allows you to access and to control inference results obtained from Intel® DL Streamer plugin elements, such as <strong>gvainference</strong>, <strong>gvadetect</strong>, <strong>gvaclassify</strong>. In Intel® DL Streamer, all inference results (both raw and interpreted) are passing through GStreamer pipeline being attached to GstBuffer objects as GStreamer metadata.</p>
<p>For better developer experience we provide Intel® DL Streamer API (C++ and Python versions) which simplifies any job you want to perform on inference results, like consuming and further reusing, additional custom post-processing, and more. Also, most of the times, Intel® DL Streamer API allows you to abstract from internal inference results as GStreamer metadata.</p>
<p>In Intel® DL Streamer API, most of the job is done by these classes: GVA::VideoFrame, GVA::RegionOfInterest &amp; GVA::Tensor (C++ version is referenced here, but Python version is available as well). Take a look at schematic picture below, which represents how these classes relate.</p>
<dl class="simple">
<dt>:raw-html-m2r:<a href="#id1"><span class="problematic" id="id2">`</span></a>&lt;div align=”center”&gt;</dt><dd><p>&lt;img width=”auto” height=”auto” src=”GVA_API.png” alt=”Intel® Deep Learning Streamer (Intel® DL Streamer) metadata API classes”&gt;</p>
</dd>
</dl>
<p>&lt;/div&gt;`
<span class="raw-html-m2r"><br></span></p>
<p>On this picture you can see 3 classes mentioned above. GVA::VideoFrame is the most high-level object, which is constructed from GstBuffer. It means that GVA::VideoFrame represents one image (one video frame). One GVA::VideoFrame can contain from 0 to many GVA::RegionOfInterest objects (ROI on picture above). GVA::RegionOfInterest describes detected object, e.g. its bounding box coordinates and label. Number of GVA::RegionOfInterest objects added to GVA::VideoFrame depends on whether detection already happened on this image (by <strong>gvadetect</strong> element in a pipeline) and whether this image contains patterns which are recognized by detection models (for example, it could be image with humans faces and detection model, which was trained to detect faces).</p>
<p>Similar, one GVA::VideoFrame can contain from 0 to many GVA::Tensor objects, which are products of running inference (by <strong>gvainference</strong> element in a pipeline) on full video frame. Such GVA::Tensor contains raw inference result which can be consumed and post-processed (interpreted) any way you like. For example, if you have custom detection model, which is not supported by <strong>gvadetect</strong>, you can run inference with <strong>gvainference</strong> element in a pipeline, and obtain results as a GVA::Tensor object. You can then use these results for getting regions of interest of this frame with your post-processing algorithm, and add your own GVA::RegionOfInterest to GVA::VideoFrame with GVA::VideoFrame::add_region. Tutorial devoted to this use case you can find in <code class="docutils literal notranslate"><span class="pre">Custom</span> <span class="pre">post-processing</span> <span class="pre">tutorial</span></code> section.</p>
<p>GVA::RegionOfInterest can also contain multiple GVA::Tensor objects, which are products of running classification (by <strong>gvaclassify</strong> element in a pipeline) on GVA::RegionOfInterest they belong to. Such GVA::Tensor can contain GVA::Tensor::label which is string containing interpreted classification result (examples are person’s age, car’s color, etc.). GVA::Tensor also stores raw data (model output blob), which can be obtained with GVA::Tensor::data. Normally, one GVA::Tensor contains some additional detection information, which can be obtained with GVA::RegionOfInterest::detection. You can check if GVA::Tensor is detection tensor with GVA::Tensor::is_detection. Detection GVA::Tensor extends detection information contained in GVA::RegionOfInterest.</p>
<p>Any modification you perform using Intel® DL Streamer API will affect underlying metadata as though you modified it directly. For example, you can add GVA::RegionOfInterest or GVA::Tensor objects to GVA::VideoFrame, and real GStreamer metadata instances will be added to GstBuffer of current GVA::VideoFrame. It means, the objects you added will behave as if they were produced by GVA elements mentioned above. You will be able to reach these objects further by pipeline using both internal metadata representation and Intel® DL Streamer API. Also, any Intel® DL Streamer elements that rely on inference results will employ objects you added. For example, <strong>gvawatermark</strong> will render on screen these objects (for example, it will draw bounding box for added GVA::RegionOfInterest).</p>
</section>
<section id="inference-results-flow">
<h2>Inference results flow<a class="headerlink" href="#inference-results-flow" title="Permalink to this heading">#</a></h2>
<p>Video analytics pipeline is a GStreamer pipeline with one or several Intel® DL Streamer elements for inference and additional actions (publishing, rendering, etc.) if needed. Take a look at this pipeline:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span><span class="nv">INPUT</span><span class="o">=</span>video.mp4
<span class="nv">MODEL1</span><span class="o">=</span>face-detection-adas-0001
<span class="nv">MODEL2</span><span class="o">=</span>age-gender-recognition-retail-0013
<span class="nv">MODEL3</span><span class="o">=</span>emotions-recognition-retail-0003

gst-launch-1.0<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>filesrc<span class="w"> </span><span class="nv">location</span><span class="o">=</span><span class="si">${</span><span class="nv">INPUT</span><span class="si">}</span><span class="w"> </span>!<span class="w"> </span>decodebin<span class="w"> </span>!<span class="w"> </span>video/x-raw<span class="w"> </span>!<span class="w"> </span>videoconvert<span class="w"> </span>!<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>gvadetect<span class="w">   </span><span class="nv">model</span><span class="o">=</span><span class="k">$(</span>MODEL_PATH<span class="w"> </span><span class="nv">$MODEL1</span><span class="k">)</span><span class="w"> </span>!<span class="w"> </span>queue<span class="w"> </span>!<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>gvaclassify<span class="w"> </span><span class="nv">model</span><span class="o">=</span><span class="k">$(</span>MODEL_PATH<span class="w"> </span><span class="nv">$MODEL2</span><span class="k">)</span><span class="w"> </span>model-proc<span class="o">=</span><span class="k">$(</span>PROC_PATH<span class="w"> </span><span class="nv">$MODEL2</span><span class="k">)</span><span class="w"> </span>!<span class="w"> </span>queue<span class="w"> </span>!<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>gvaclassify<span class="w"> </span><span class="nv">model</span><span class="o">=</span><span class="k">$(</span>MODEL_PATH<span class="w"> </span><span class="nv">$MODEL3</span><span class="k">)</span><span class="w"> </span>model-proc<span class="o">=</span><span class="k">$(</span>PROC_PATH<span class="w"> </span><span class="nv">$MODEL3</span><span class="k">)</span><span class="w"> </span>!<span class="w"> </span>queue<span class="w"> </span>!<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>gvawatermark<span class="w"> </span>!<span class="w"> </span>videoconvert<span class="w"> </span>!<span class="w"> </span>fpsdisplaysink<span class="w"> </span>video-sink<span class="o">=</span>xvimagesink<span class="w"> </span><span class="nv">sync</span><span class="o">=</span><span class="nb">false</span>
</pre></div>
</div>
<p>Note: following explanation is based on C++ Intel® DL Streamer API, but Python Intel® DL Streamer API can be used in the same way</p>
<p>Here, <strong>gvadetect</strong> runs face detection on each frame (GVA::VideoFrame) of provided video file. Let’s say it detected 3 faces on particular frame. It means that 3 instances of GVA::RegionOfInterest will be added to this frame. Also, each GVA::RegionOfInterest will get its own detection GVA::Tensor attached. Such GVA::Tensor contains additional detection information.</p>
<p>After detection frame goes into first of two <strong>gvaclassify</strong> elements, which will iterate by 3 instances of GVA::RegionOfInterest added to GVA::VideoFrame. For each GVA::RegionOfInterest it will take region itself from full frame and run age &amp; gender classification on this region. Thus, each person detected will also get age and gender classified. It’s achieved by adding 2 GVA::Tensor instances to current GVA::RegionOfInterest (one for age and one for gender).</p>
<p>After first classification frame goes into second <strong>gvaclassify</strong> element, which does the same job as previous <strong>gvaclassify</strong> element, but it classifies person’s emotion, instead of age &amp; gender. Result emotion will be contained in its own GVA::Tensor added to current GVA::RegionOfInterest.</p>
<p>Thus, after detection &amp; classification part of pipeline we have GVA::VideoFrame with 3 instances of GVA::RegionOfInterest added, and 4 instances of GVA::Tensor added to each of 3 instances of GVA::RegionOfInterest. On image level, it means that we’ve got 3 persons detected, and age, gender &amp; emotion of each of them is classified.</p>
<p>Last Intel® DL Streamer element in the pipeline is <strong>gvawatermark</strong> and its job is to display inference results on top of frame currently rendered on screen. To do this, it creates GVA::VideoFrame instance for current frame and iterates by attached GVA::RegionOfInterest instances, and by GVA::Tensor instances, attached to each of GVA::RegionOfInterest. This way, you will see bounding boxes drawn around persons faces, and these boxes will also be labeled with age, gender &amp; emotion.</p>
<p>The whole point of Intel® DL Streamer API is to allow you to access any object we described above in any point of pipeline. You can read it, modify it, add your own tensors and regions of interest, and so on. Thus, you can add custom post-processing for any deep learning model in case Intel® DL Streamer inference elements don’t support it. There is a handy <strong>gvainference</strong> element, which adds raw inference result (output layer blob) in GVA::Tensor, so you can do custom post-processing on it.</p>
</section>
<section id="print-inference-results-example">
<h2>Print inference results example<a class="headerlink" href="#print-inference-results-example" title="Permalink to this heading">#</a></h2>
<p>Here we provide a few code snippets, which print some of inference results obtained from video analytics pipeline. They are different ways to achieve the same thing.
To get thorough understanding of how to create an application which takes advantage of Intel® DL Streamer API, make sure to check out the rest of this document.</p>
<section id="access-inference-results-with-low-level-c-code">
<h3>1. Access inference results with low-level C code<a class="headerlink" href="#access-inference-results-with-low-level-c-code" title="Permalink to this heading">#</a></h3>
<p>This is not recommended way of dealing with inference results obtained from video analytics pipeline and should be avoided unless some specific considerations exist</p>
<div class="highlight-c notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span> <span class="cpf">&lt;gst/video/video.h&gt; // contains GstVideoRegionOfInterestMeta</span>

<span class="kt">void</span> <span class="nf">PrintMeta</span><span class="p">(</span><span class="n">GstBuffer</span> <span class="o">*</span><span class="n">buffer</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">gpointer</span> <span class="n">state</span> <span class="o">=</span> <span class="nb">NULL</span><span class="p">;</span>
    <span class="n">GstMeta</span> <span class="o">*</span><span class="n">meta</span> <span class="o">=</span> <span class="nb">NULL</span><span class="p">;</span>
    <span class="k">while</span> <span class="p">((</span><span class="n">meta</span> <span class="o">=</span> <span class="n">gst_buffer_iterate_meta</span><span class="p">(</span><span class="n">buffer</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">state</span><span class="p">))</span> <span class="o">!=</span> <span class="nb">NULL</span><span class="p">)</span> <span class="p">{</span> <span class="c1">// iterate by meta attached to buffer</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">meta</span><span class="o">-&gt;</span><span class="n">info</span><span class="o">-&gt;</span><span class="n">api</span> <span class="o">!=</span> <span class="n">GST_VIDEO_REGION_OF_INTEREST_META_API_TYPE</span><span class="p">)</span>
            <span class="k">continue</span><span class="p">;</span> <span class="c1">// we only interested in GstVideoRegionOfInterestMeta instances, because it&#39;s produced by gvadetect</span>
        <span class="n">GstVideoRegionOfInterestMeta</span> <span class="o">*</span><span class="n">roi_meta</span> <span class="o">=</span> <span class="p">(</span><span class="n">GstVideoRegionOfInterestMeta</span><span class="o">*</span><span class="p">)</span><span class="n">meta</span><span class="p">;</span>
        <span class="n">printf</span><span class="p">(</span><span class="s">&quot;Object bounding box %d,%d,%d,%d</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span> <span class="n">roi_meta</span><span class="o">-&gt;</span><span class="n">x</span><span class="p">,</span> <span class="n">roi_meta</span><span class="o">-&gt;</span><span class="n">y</span><span class="p">,</span> <span class="n">roi_meta</span><span class="o">-&gt;</span><span class="n">w</span><span class="p">,</span> <span class="n">roi_meta</span><span class="o">-&gt;</span><span class="n">h</span><span class="p">);</span>
        <span class="k">for</span> <span class="p">(</span><span class="n">GList</span> <span class="o">*</span><span class="n">l</span> <span class="o">=</span> <span class="n">roi_meta</span><span class="o">-&gt;</span><span class="n">params</span><span class="p">;</span> <span class="n">l</span><span class="p">;</span> <span class="n">l</span> <span class="o">=</span> <span class="n">g_list_next</span><span class="p">(</span><span class="n">l</span><span class="p">))</span> <span class="p">{</span> <span class="c1">// iterate by tensors attached to this region of interest</span>
            <span class="n">GstStructure</span> <span class="o">*</span><span class="n">structure</span> <span class="o">=</span> <span class="p">(</span><span class="n">GstStructure</span> <span class="o">*</span><span class="p">)</span> <span class="n">l</span><span class="o">-&gt;</span><span class="n">data</span><span class="p">;</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">gst_structure_has_name</span><span class="p">(</span><span class="n">structure</span><span class="p">,</span> <span class="s">&quot;detection&quot;</span><span class="p">))</span>
                <span class="k">continue</span><span class="p">;</span> <span class="c1">// detection tensor doesn&#39;t contain classification result and hence doesn&#39;t contain label</span>
            <span class="c1">// print some tensor information</span>
            <span class="n">printf</span><span class="p">(</span><span class="s">&quot;  Attribute %s</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span> <span class="n">gst_structure_get_name</span><span class="p">(</span><span class="n">structure</span><span class="p">));</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">gst_structure_has_field</span><span class="p">(</span><span class="n">structure</span><span class="p">,</span> <span class="s">&quot;label&quot;</span><span class="p">))</span> <span class="p">{</span>
                <span class="n">printf</span><span class="p">(</span><span class="s">&quot;    label=%s</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span> <span class="n">gst_structure_get_string</span><span class="p">(</span><span class="n">structure</span><span class="p">,</span> <span class="s">&quot;label&quot;</span><span class="p">));</span>
            <span class="p">}</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">gst_structure_has_field</span><span class="p">(</span><span class="n">structure</span><span class="p">,</span> <span class="s">&quot;confidence&quot;</span><span class="p">))</span> <span class="p">{</span>
                <span class="kt">double</span> <span class="n">confidence</span><span class="p">;</span>
                <span class="n">gst_structure_get_double</span><span class="p">(</span><span class="n">structure</span><span class="p">,</span> <span class="s">&quot;confidence&quot;</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">confidence</span><span class="p">);</span>
                <span class="n">printf</span><span class="p">(</span><span class="s">&quot;    confidence=%.2f</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span> <span class="n">confidence</span><span class="p">);</span>
            <span class="p">}</span>
        <span class="p">}</span>
    <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section id="access-inference-results-with-c-api">
<h3>2. Access inference results with C++ API<a class="headerlink" href="#access-inference-results-with-c-api" title="Permalink to this heading">#</a></h3>
<p>This is recommended way of dealing with inference results obtained from video analytics pipeline from C++ application</p>
<div class="highlight-c notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span> <span class="cpf">&quot;video_frame.h&quot; // contains GVA::VideoFrame, GVA::RegionOfInterest and GVA::Tensor</span>

<span class="kt">void</span> <span class="nf">PrintMeta</span><span class="p">(</span><span class="n">GstBuffer</span> <span class="o">*</span><span class="n">buffer</span><span class="p">,</span> <span class="n">GstCaps</span> <span class="o">*</span><span class="n">caps</span><span class="p">)</span> <span class="p">{</span> <span class="c1">// simple function to display some tensor information</span>
    <span class="n">GVA</span><span class="o">::</span><span class="n">VideoFrame</span> <span class="n">video_frame</span><span class="p">(</span><span class="n">buffer</span><span class="p">,</span> <span class="n">caps</span><span class="p">);</span>
    <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">GVA</span><span class="o">::</span><span class="n">RegionOfInterest</span><span class="o">&gt;</span> <span class="n">regions</span> <span class="o">=</span> <span class="n">video_frame</span><span class="p">.</span><span class="n">regions</span><span class="p">();</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">GVA</span><span class="o">::</span><span class="n">RegionOfInterest</span> <span class="o">&amp;</span><span class="nl">roi</span> <span class="p">:</span> <span class="n">regions</span><span class="p">)</span> <span class="p">{</span> <span class="c1">// iterate by regions of interest attached to this video frame</span>
        <span class="k">auto</span> <span class="n">bbox</span> <span class="o">=</span> <span class="n">roi</span><span class="p">.</span><span class="n">rect</span><span class="p">();</span> <span class="c1">// get bounding box information</span>
        <span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">&quot;Object bounding box &quot;</span> <span class="o">&lt;&lt;</span> <span class="n">bbox</span><span class="p">.</span><span class="n">x</span> <span class="o">&lt;&lt;</span> <span class="s">&quot;,&quot;</span> <span class="o">&lt;&lt;</span> <span class="n">bbox</span><span class="p">.</span><span class="n">y</span> <span class="o">&lt;&lt;</span> <span class="s">&quot;,&quot;</span> <span class="o">&lt;&lt;</span> <span class="n">bbox</span><span class="p">.</span><span class="n">w</span> <span class="o">&lt;&lt;</span> <span class="s">&quot;,&quot;</span> <span class="o">&lt;&lt;</span> <span class="n">bbox</span><span class="p">.</span><span class="n">h</span> <span class="o">&lt;&lt;</span> <span class="s">&quot;,&quot;</span> <span class="o">&lt;&lt;</span> <span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
        <span class="k">for</span> <span class="p">(</span><span class="k">const</span> <span class="n">GVA</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="nl">tensor</span> <span class="p">:</span> <span class="n">roi</span><span class="p">.</span><span class="n">tensors</span><span class="p">())</span> <span class="p">{</span> <span class="c1">// iterate by tensors attached to this region of interest</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">tensor</span><span class="p">.</span><span class="n">is_detection</span><span class="p">())</span>
                <span class="k">continue</span><span class="p">;</span> <span class="c1">// detection tensor doesn&#39;t contain classification result and hence doesn&#39;t contain label</span>
            <span class="c1">// print some tensor information</span>
            <span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">&quot;  Attribute &quot;</span>     <span class="o">&lt;&lt;</span> <span class="n">tensor</span><span class="p">.</span><span class="n">name</span><span class="p">()</span>       <span class="o">&lt;&lt;</span> <span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
            <span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">&quot;    label= &quot;</span>      <span class="o">&lt;&lt;</span> <span class="n">tensor</span><span class="p">.</span><span class="n">label</span><span class="p">()</span>      <span class="o">&lt;&lt;</span> <span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
            <span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">&quot;    confidence= &quot;</span> <span class="o">&lt;&lt;</span> <span class="n">tensor</span><span class="p">.</span><span class="n">confidence</span><span class="p">()</span> <span class="o">&lt;&lt;</span> <span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
        <span class="p">}</span>
    <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section id="access-inference-results-with-python-api">
<h3>3. Access inference results with Python API<a class="headerlink" href="#access-inference-results-with-python-api" title="Permalink to this heading">#</a></h3>
<p>This is recommended way of dealing with inference results obtained from video analytics pipeline from Python code (via Python application or via <code class="docutils literal notranslate"><span class="pre">gvapython</span></code> element in pipeline)</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">gi</span>
<span class="n">gi</span><span class="o">.</span><span class="n">require_version</span><span class="p">(</span><span class="s1">&#39;Gst&#39;</span><span class="p">,</span> <span class="s1">&#39;1.0&#39;</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">gi.repository</span> <span class="kn">import</span> <span class="n">Gst</span>  <span class="c1"># contains GStreamer entities</span>
<span class="kn">from</span> <span class="nn">gstgva</span> <span class="kn">import</span> <span class="n">VideoFrame</span>

<span class="k">def</span> <span class="nf">PrintMeta</span><span class="p">(</span><span class="n">buffer</span><span class="p">:</span> <span class="n">Gst</span><span class="o">.</span><span class="n">Buffer</span><span class="p">,</span> <span class="n">caps</span><span class="p">:</span> <span class="n">Gst</span><span class="o">.</span><span class="n">Caps</span><span class="p">):</span>  <span class="c1"># simple function to display some tensor information</span>
    <span class="n">frame</span> <span class="o">=</span> <span class="n">VideoFrame</span><span class="p">(</span><span class="n">buffer</span><span class="p">,</span> <span class="n">caps</span><span class="o">=</span><span class="n">caps</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">roi</span> <span class="ow">in</span> <span class="n">frame</span><span class="o">.</span><span class="n">regions</span><span class="p">():</span>  <span class="c1"># iterate by regions of interest attached to this video frame</span>
        <span class="n">bbox</span> <span class="o">=</span> <span class="n">roi</span><span class="o">.</span><span class="n">rect</span><span class="p">()</span>  <span class="c1"># get bounding box information</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Object bounding box </span><span class="si">{}</span><span class="s2">, </span><span class="si">{}</span><span class="s2">, </span><span class="si">{}</span><span class="s2">, </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">bbox</span><span class="o">.</span><span class="n">x</span><span class="p">,</span> <span class="n">bbox</span><span class="o">.</span><span class="n">y</span><span class="p">,</span> <span class="n">bbox</span><span class="o">.</span><span class="n">w</span><span class="p">,</span> <span class="n">bbox</span><span class="o">.</span><span class="n">h</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">tensor</span> <span class="ow">in</span> <span class="n">roi</span><span class="o">.</span><span class="n">tensors</span><span class="p">():</span>  <span class="c1"># iterate by tensors attached to this region of interest</span>
            <span class="k">if</span> <span class="n">tensor</span><span class="o">.</span><span class="n">is_detection</span><span class="p">():</span>
                <span class="k">continue</span>  <span class="c1"># detection tensor doesn&#39;t contain classification result and hence doesn&#39;t contain label</span>
            <span class="c1"># print some tensor information</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  Attribute </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">tensor</span><span class="o">.</span><span class="n">name</span><span class="p">()))</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;    label= </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">tensor</span><span class="o">.</span><span class="n">label</span><span class="p">()))</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;    confidence= </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">tensor</span><span class="o">.</span><span class="n">confidence</span><span class="p">()))</span>
</pre></div>
</div>
</section>
</section>
<section id="custom-post-processing-tutorial">
<h2>Custom post-processing tutorial<a class="headerlink" href="#custom-post-processing-tutorial" title="Permalink to this heading">#</a></h2>
<p>There are several ways how you can access inference results provided by Intel® DL Streamer elements in GStreamer pipeline using Intel® DL Streamer API:</p>
<ol class="arabic simple">
<li><p>Create <strong>C++/Python</strong> application, which sets up callback on buffer passing through any Intel® DL Streamer element and runs video analytics pipeline. In the body of this callback GstBuffer and, hence, Intel® DL Streamer API will be available</p></li>
<li><p>Create <strong>C++/Python</strong> application, which runs video analytics pipeline with standard appsink element added as sink. You will then be able to register callback on GstBuffer incoming to appsink</p></li>
<li><p>Write your own GStreamer plugin which has access to GstBuffers coming through and insert it to pipeline after Intel® DL Streamer inference elements</p></li>
</ol>
<p>We’ve got plenty examples of following ways 1 &amp; 2 in our samples and most existing Intel® DL Streamer elements relying on existing inference result are basically based on 3rd way (e.g. <strong>gvaclassify</strong>, <strong>gvatrack</strong>, and more). Let’s focus on one specific task: let’s say, you have very specific deep learning model, which requires custom post-processing (<strong>gvadetect</strong> is not able to correctly interpret inference results of some models you can train or find on Web). You know how post processing should be implemented, but you don’t know how to get and make any use of inference results produced by video analytics pipeline. To solve this task, you will need <strong>gvainference</strong> element, which runs deep learning model inference on passing video frame and stores raw inference result in a form of GVA::Tensor, attached to GVA::VideoFrame. So we use <strong>gvainference</strong> to get tensors, but how do we access these produced tensors?</p>
<p>Any of 3 approaches above will suffice. For the clarity of explanation, let’s choose 1st one and focus on it. Also, for our tutorial we will add “custom” post-processing for SSD-like models. <strong>gvadetect</strong> already implements this type of post-processing, but here we will use <strong>gvainference</strong> and set up post-processing as callback. In your case, you will need to only put your post-processing code instead of ours.</p>
<p>Below you can see full snippet of <strong>Python</strong> code that is ready to solve your task. Take a look, and then we will talk about it closely. Note, that almost the same code can be written in <strong>C++</strong>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">from</span> <span class="nn">argparse</span> <span class="kn">import</span> <span class="n">ArgumentParser</span>
<span class="kn">import</span> <span class="nn">gi</span>  <span class="c1"># get Python bindings for GLib-based libraries</span>
<span class="n">gi</span><span class="o">.</span><span class="n">require_version</span><span class="p">(</span><span class="s1">&#39;GstVideo&#39;</span><span class="p">,</span> <span class="s1">&#39;1.0&#39;</span><span class="p">)</span>
<span class="n">gi</span><span class="o">.</span><span class="n">require_version</span><span class="p">(</span><span class="s1">&#39;Gst&#39;</span><span class="p">,</span> <span class="s1">&#39;1.0&#39;</span><span class="p">)</span>
<span class="n">gi</span><span class="o">.</span><span class="n">require_version</span><span class="p">(</span><span class="s1">&#39;GObject&#39;</span><span class="p">,</span> <span class="s1">&#39;2.0&#39;</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">gi.repository</span> <span class="kn">import</span> <span class="n">Gst</span><span class="p">,</span> <span class="n">GstVideo</span><span class="p">,</span> <span class="n">GObject</span>

<span class="c1"># Intel® DL Streamer API modules</span>
<span class="kn">from</span> <span class="nn">gstgva</span> <span class="kn">import</span> <span class="n">VideoFrame</span><span class="p">,</span> <span class="n">util</span>

<span class="n">parser</span> <span class="o">=</span> <span class="n">ArgumentParser</span><span class="p">(</span><span class="n">add_help</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">_args</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">add_argument_group</span><span class="p">(</span><span class="s1">&#39;Options&#39;</span><span class="p">)</span>
<span class="n">_args</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;-i&quot;</span><span class="p">,</span> <span class="s2">&quot;--input&quot;</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Required. Path to input video file&quot;</span><span class="p">,</span>
                   <span class="n">required</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">)</span>
<span class="n">_args</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;-d&quot;</span><span class="p">,</span> <span class="s2">&quot;--detection_model&quot;</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Required. Path to an .xml file with object detection model&quot;</span><span class="p">,</span>
                   <span class="n">required</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">)</span>

<span class="c1"># init GStreamer</span>
<span class="n">Gst</span><span class="o">.</span><span class="n">init</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">argv</span><span class="p">)</span>

<span class="c1"># post-processing code</span>
<span class="k">def</span> <span class="nf">process_frame</span><span class="p">(</span><span class="n">frame</span><span class="p">:</span> <span class="n">VideoFrame</span><span class="p">,</span> <span class="n">threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
    <span class="n">width</span> <span class="o">=</span> <span class="n">frame</span><span class="o">.</span><span class="n">video_info</span><span class="p">()</span><span class="o">.</span><span class="n">width</span>
    <span class="n">height</span> <span class="o">=</span> <span class="n">frame</span><span class="o">.</span><span class="n">video_info</span><span class="p">()</span><span class="o">.</span><span class="n">height</span>

    <span class="k">for</span> <span class="n">tensor</span> <span class="ow">in</span> <span class="n">frame</span><span class="o">.</span><span class="n">tensors</span><span class="p">():</span>
        <span class="n">dims</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">dims</span><span class="p">()</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">data</span><span class="p">()</span>
        <span class="n">object_size</span> <span class="o">=</span> <span class="n">dims</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">dims</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]):</span>
            <span class="n">image_id</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="n">object_size</span> <span class="o">+</span> <span class="mi">0</span><span class="p">]</span>
            <span class="n">confidence</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="n">object_size</span> <span class="o">+</span> <span class="mi">2</span><span class="p">]</span>
            <span class="n">x_min</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="n">object_size</span> <span class="o">+</span> <span class="mi">3</span><span class="p">]</span> <span class="o">*</span> <span class="n">width</span> <span class="o">+</span> <span class="mf">0.5</span><span class="p">)</span>
            <span class="n">y_min</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="n">object_size</span> <span class="o">+</span> <span class="mi">4</span><span class="p">]</span> <span class="o">*</span> <span class="n">height</span> <span class="o">+</span> <span class="mf">0.5</span><span class="p">)</span>
            <span class="n">x_max</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="n">object_size</span> <span class="o">+</span> <span class="mi">5</span><span class="p">]</span> <span class="o">*</span> <span class="n">width</span> <span class="o">+</span> <span class="mf">0.5</span><span class="p">)</span>
            <span class="n">y_max</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="n">object_size</span> <span class="o">+</span> <span class="mi">6</span><span class="p">]</span> <span class="o">*</span> <span class="n">height</span> <span class="o">+</span> <span class="mf">0.5</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">image_id</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">break</span>
            <span class="k">if</span> <span class="n">confidence</span> <span class="o">&lt;</span> <span class="n">threshold</span><span class="p">:</span>
                <span class="k">continue</span>

            <span class="n">frame</span><span class="o">.</span><span class="n">add_region</span><span class="p">(</span><span class="n">x_min</span><span class="p">,</span> <span class="n">y_min</span><span class="p">,</span> <span class="n">x_max</span> <span class="o">-</span> <span class="n">x_min</span><span class="p">,</span> <span class="n">y_max</span> <span class="o">-</span> <span class="n">y_min</span><span class="p">,</span> <span class="s2">&quot;car&quot;</span><span class="p">,</span> <span class="n">confidence</span><span class="p">)</span>

    <span class="k">return</span> <span class="kc">True</span>

<span class="k">def</span> <span class="nf">detect_postproc_callback</span><span class="p">(</span><span class="n">pad</span><span class="p">,</span> <span class="n">info</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">util</span><span class="o">.</span><span class="n">GST_PAD_PROBE_INFO_BUFFER</span><span class="p">(</span><span class="n">info</span><span class="p">)</span> <span class="k">as</span> <span class="n">buffer</span><span class="p">:</span>
        <span class="n">caps</span> <span class="o">=</span> <span class="n">pad</span><span class="o">.</span><span class="n">get_current_caps</span><span class="p">()</span>
        <span class="n">frame</span> <span class="o">=</span> <span class="n">VideoFrame</span><span class="p">(</span><span class="n">buffer</span><span class="p">,</span> <span class="n">caps</span><span class="o">=</span><span class="n">caps</span><span class="p">)</span>
        <span class="n">status</span> <span class="o">=</span> <span class="n">process_frame</span><span class="p">(</span><span class="n">frame</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">Gst</span><span class="o">.</span><span class="n">PadProbeReturn</span><span class="o">.</span><span class="n">OK</span> <span class="k">if</span> <span class="n">status</span> <span class="k">else</span> <span class="n">Gst</span><span class="o">.</span><span class="n">PadProbeReturn</span><span class="o">.</span><span class="n">DROP</span>

<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="n">args</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_args</span><span class="p">()</span>

    <span class="c1"># build pipeline using parse_launch</span>
    <span class="n">pipeline_str</span> <span class="o">=</span> <span class="s2">&quot;filesrc location=</span><span class="si">{}</span><span class="s2"> ! decodebin ! videoconvert ! video/x-raw,format=BGRx ! &quot;</span> \
        <span class="s2">&quot;gvainference name=gvainference model=</span><span class="si">{}</span><span class="s2"> ! queue ! &quot;</span> \
        <span class="s2">&quot;gvawatermark ! videoconvert ! fpsdisplaysink video-sink=xvimagesink sync=false&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
            <span class="n">args</span><span class="o">.</span><span class="n">input</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">detection_model</span><span class="p">)</span>
    <span class="n">pipeline</span> <span class="o">=</span> <span class="n">Gst</span><span class="o">.</span><span class="n">parse_launch</span><span class="p">(</span><span class="n">pipeline_str</span><span class="p">)</span>

    <span class="c1"># set callback</span>
    <span class="n">gvainference</span> <span class="o">=</span> <span class="n">pipeline</span><span class="o">.</span><span class="n">get_by_name</span><span class="p">(</span><span class="s2">&quot;gvainference&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">gvainference</span><span class="p">:</span>
        <span class="n">pad</span> <span class="o">=</span> <span class="n">gvainference</span><span class="o">.</span><span class="n">get_static_pad</span><span class="p">(</span><span class="s2">&quot;src&quot;</span><span class="p">)</span>
        <span class="n">pad</span><span class="o">.</span><span class="n">add_probe</span><span class="p">(</span><span class="n">Gst</span><span class="o">.</span><span class="n">PadProbeType</span><span class="o">.</span><span class="n">BUFFER</span><span class="p">,</span> <span class="n">detect_postproc_callback</span><span class="p">)</span>

    <span class="c1"># start pipeline</span>
    <span class="n">pipeline</span><span class="o">.</span><span class="n">set_state</span><span class="p">(</span><span class="n">Gst</span><span class="o">.</span><span class="n">State</span><span class="o">.</span><span class="n">PLAYING</span><span class="p">)</span>

    <span class="c1"># wait until EOS or error</span>
    <span class="n">bus</span> <span class="o">=</span> <span class="n">pipeline</span><span class="o">.</span><span class="n">get_bus</span><span class="p">()</span>
    <span class="n">msg</span> <span class="o">=</span> <span class="n">bus</span><span class="o">.</span><span class="n">timed_pop_filtered</span><span class="p">(</span>
        <span class="n">Gst</span><span class="o">.</span><span class="n">CLOCK_TIME_NONE</span><span class="p">,</span> <span class="n">Gst</span><span class="o">.</span><span class="n">MessageType</span><span class="o">.</span><span class="n">ERROR</span> <span class="o">|</span> <span class="n">Gst</span><span class="o">.</span><span class="n">MessageType</span><span class="o">.</span><span class="n">EOS</span><span class="p">)</span>

    <span class="c1"># free pipeline</span>
    <span class="n">pipeline</span><span class="o">.</span><span class="n">set_state</span><span class="p">(</span><span class="n">Gst</span><span class="o">.</span><span class="n">State</span><span class="o">.</span><span class="n">NULL</span><span class="p">)</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="n">sys</span><span class="o">.</span><span class="n">exit</span><span class="p">(</span><span class="n">main</span><span class="p">()</span> <span class="ow">or</span> <span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
<p>Let’s go through the most interesting pieces. First, we import necessary Python modules:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">from</span> <span class="nn">argparse</span> <span class="kn">import</span> <span class="n">ArgumentParser</span>
<span class="kn">import</span> <span class="nn">gi</span>  <span class="c1"># get Python bindings for GLib-based libraries</span>
<span class="n">gi</span><span class="o">.</span><span class="n">require_version</span><span class="p">(</span><span class="s1">&#39;GstVideo&#39;</span><span class="p">,</span> <span class="s1">&#39;1.0&#39;</span><span class="p">)</span>
<span class="n">gi</span><span class="o">.</span><span class="n">require_version</span><span class="p">(</span><span class="s1">&#39;Gst&#39;</span><span class="p">,</span> <span class="s1">&#39;1.0&#39;</span><span class="p">)</span>
<span class="n">gi</span><span class="o">.</span><span class="n">require_version</span><span class="p">(</span><span class="s1">&#39;GObject&#39;</span><span class="p">,</span> <span class="s1">&#39;2.0&#39;</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">gi.repository</span> <span class="kn">import</span> <span class="n">Gst</span><span class="p">,</span> <span class="n">GstVideo</span><span class="p">,</span> <span class="n">GObject</span>

<span class="c1"># Intel® DL Streamer API modules</span>
<span class="kn">from</span> <span class="nn">gstgva</span> <span class="kn">import</span> <span class="n">VideoFrame</span><span class="p">,</span> <span class="n">util</span>
</pre></div>
</div>
<p>Then, we parse command-line arguments. When run this script, you should specify input video with “-i” and your detection model with “-d”:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">parser</span> <span class="o">=</span> <span class="n">ArgumentParser</span><span class="p">(</span><span class="n">add_help</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">_args</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">add_argument_group</span><span class="p">(</span><span class="s1">&#39;Options&#39;</span><span class="p">)</span>
<span class="n">_args</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;-i&quot;</span><span class="p">,</span> <span class="s2">&quot;--input&quot;</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Required. Path to input video file&quot;</span><span class="p">,</span>
                   <span class="n">required</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">)</span>
<span class="n">_args</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;-d&quot;</span><span class="p">,</span> <span class="s2">&quot;--detection_model&quot;</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Required. Path to an .xml file with object detection model&quot;</span><span class="p">,</span>
                   <span class="n">required</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">)</span>
</pre></div>
</div>
<p>Next, function <code class="docutils literal notranslate"><span class="pre">process_frame</span></code> defines post-processing. As we said above, this code is for SSD-like models, so please feel free to replace it with your own post-processing implementation that suffices your custom model. Meanwhile, let’s take a look at usage of Intel® DL Streamer API in this piece.</p>
<p>Tons of image information regarding current video frame can be obtain with gstgva.video_frame.VideoFrame.video_info. You can get image width, height, channels format and much more:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">width</span> <span class="o">=</span> <span class="n">frame</span><span class="o">.</span><span class="n">video_info</span><span class="p">()</span><span class="o">.</span><span class="n">width</span>
<span class="n">height</span> <span class="o">=</span> <span class="n">frame</span><span class="o">.</span><span class="n">video_info</span><span class="p">()</span><span class="o">.</span><span class="n">height</span>
</pre></div>
</div>
<p>Next, we iterate by gstgva.video_frame.VideoFrame.tensors, which were added by <strong>gvainference</strong>. We can get some inference result information, like gstgva.tensor.Tensor.dims (list of model output blob dimensions) and gstgva.tensor.Tensor.data (raw output blob to interpret with your post-processing code):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">tensor</span> <span class="ow">in</span> <span class="n">frame</span><span class="o">.</span><span class="n">tensors</span><span class="p">():</span>
    <span class="n">dims</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">dims</span><span class="p">()</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">data</span><span class="p">()</span>
</pre></div>
</div>
<p>After we eject bounding box parameters from raw inference blob, we are ready to call gstgva.video_frame.VideoFrame.add_region with box coordinates, label and confidence as parameters.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">frame</span><span class="o">.</span><span class="n">add_region</span><span class="p">(</span><span class="n">x_min</span><span class="p">,</span> <span class="n">y_min</span><span class="p">,</span> <span class="n">x_max</span> <span class="o">-</span> <span class="n">x_min</span><span class="p">,</span> <span class="n">y_max</span> <span class="o">-</span> <span class="n">y_min</span><span class="p">,</span> <span class="s2">&quot;car&quot;</span><span class="p">,</span> <span class="n">confidence</span><span class="p">)</span>
</pre></div>
</div>
<p>Next, we define callback which will run <code class="docutils literal notranslate"><span class="pre">process_frame</span></code> (our post-processing code) on each video frame passing by pipeline:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">detect_postproc_callback</span><span class="p">(</span><span class="n">pad</span><span class="p">,</span> <span class="n">info</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">util</span><span class="o">.</span><span class="n">GST_PAD_PROBE_INFO_BUFFER</span><span class="p">(</span><span class="n">info</span><span class="p">)</span> <span class="k">as</span> <span class="n">buffer</span><span class="p">:</span>
        <span class="n">caps</span> <span class="o">=</span> <span class="n">pad</span><span class="o">.</span><span class="n">get_current_caps</span><span class="p">()</span>
        <span class="n">frame</span> <span class="o">=</span> <span class="n">VideoFrame</span><span class="p">(</span><span class="n">buffer</span><span class="p">,</span> <span class="n">caps</span><span class="o">=</span><span class="n">caps</span><span class="p">)</span>
        <span class="n">status</span> <span class="o">=</span> <span class="n">process_frame</span><span class="p">(</span><span class="n">frame</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">Gst</span><span class="o">.</span><span class="n">PadProbeReturn</span><span class="o">.</span><span class="n">OK</span> <span class="k">if</span> <span class="n">status</span> <span class="k">else</span> <span class="n">Gst</span><span class="o">.</span><span class="n">PadProbeReturn</span><span class="o">.</span><span class="n">DROP</span>
</pre></div>
</div>
<p>In <code class="docutils literal notranslate"><span class="pre">main</span></code> function we create string template of video analytics pipeline with <strong>gvainference</strong> to run inference and <strong>gvawatermark</strong> to display bounding boxes and their labels (the ones we set to “face”):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># build pipeline using parse_launch</span>
<span class="n">pipeline_str</span> <span class="o">=</span> <span class="s2">&quot;filesrc location=</span><span class="si">{}</span><span class="s2"> ! decodebin ! videoconvert ! video/x-raw,format=BGRx ! &quot;</span> \
    <span class="s2">&quot;gvainference name=gvainference model=</span><span class="si">{}</span><span class="s2"> ! queue ! &quot;</span> \
    <span class="s2">&quot;gvawatermark ! videoconvert ! fpsdisplaysink video-sink=xvimagesink sync=false&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
    <span class="n">args</span><span class="o">.</span><span class="n">input</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">detection_model</span><span class="p">)</span>
</pre></div>
</div>
<p>Finally, we register callback on <strong>gvainference</strong> source pad (source pad is meant to produce GstBuffer):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># set callback</span>
<span class="n">gvainference</span> <span class="o">=</span> <span class="n">pipeline</span><span class="o">.</span><span class="n">get_by_name</span><span class="p">(</span><span class="s2">&quot;gvainference&quot;</span><span class="p">)</span>
<span class="k">if</span> <span class="n">gvainference</span><span class="p">:</span>
    <span class="n">pad</span> <span class="o">=</span> <span class="n">gvainference</span><span class="o">.</span><span class="n">get_static_pad</span><span class="p">(</span><span class="s2">&quot;src&quot;</span><span class="p">)</span>
    <span class="n">pad</span><span class="o">.</span><span class="n">add_probe</span><span class="p">(</span><span class="n">Gst</span><span class="o">.</span><span class="n">PadProbeType</span><span class="o">.</span><span class="n">BUFFER</span><span class="p">,</span> <span class="n">detect_postproc_callback</span><span class="p">)</span>
</pre></div>
</div>
<p>Thus, before current frame leaves <strong>gvainference</strong>, <code class="docutils literal notranslate"><span class="pre">detect_postproc_callback</span></code> with access to GstBuffer will be called, where custom post-processing code is executed.</p>
<p>At the end of application, after all frames have passed by the pipeline, playback is finished.</p>
</section>
</section>


                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#overview">Overview</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#inference-results-flow">Inference results flow</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#print-inference-results-example">Print inference results example</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#access-inference-results-with-low-level-c-code">1. Access inference results with low-level C code</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#access-inference-results-with-c-api">2. Access inference results with C++ API</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#access-inference-results-with-python-api">3. Access inference results with Python API</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#custom-post-processing-tutorial">Custom post-processing tutorial</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Intel Corporation
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2024, Intel Corporation.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=5b4479735964841361fd"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>